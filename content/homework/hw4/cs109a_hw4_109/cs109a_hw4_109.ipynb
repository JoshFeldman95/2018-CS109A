{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaoVZSrv48aE"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "## Homework 4 - Regularization \n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KsLD_en48aI"
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- **This homework must be completed individually.**\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "\n",
    "\n",
    "Names of people you have worked with goes here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KsLD_en48aI"
   },
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "O1guCDAx48aK",
    "outputId": "0aa1afea-ee13-46c0-cdf0-150d57fd1ad8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kh0dA7W48ad"
   },
   "source": [
    "import these libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j02kGLE-48ah"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "from pandas.core import datetools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing Bike Sharing Usage Data\n",
    "\n",
    "In this homework, we will focus on regularization and cross validation. We will continue to build regression models for the [Capital Bikeshare program](https://www.capitalbikeshare.com) in Washington D.C.  See homework 3 for more information about the Capital Bikeshare data that we'll be using extensively. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 1 [20pts]  Data pre-processing </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNsROjOHaAA2"
   },
   "source": [
    "**1.1** Read in the provided `bikes_student.csv` to a data frame named `bikes_main`. Split it into a training set `bikes_train` and a validation set `bikes_val`. Use `random_state=90`, a test set size of .2, and stratify on month. Remember to specify the data's index column as you read it in.\n",
    "\n",
    "**1.2** As with last homework, the response will be the `counts` column and we'll drop `counts`, `registered` and `casual` for being trivial predictors, drop `workingday` and `month` for being multicollinear with other columns, and `dteday` for being inappropriate for regression. Write code to do this.\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and **test** your code by producing `practice_y_train` and `practice_X_train`.\n",
    "\n",
    "**1.3** Write a function to standardize a provided subset of columns in your training/validation/test sets. Remember that while you will be scaling all of your data, you must learn the scaling parameters (mean and SD) from only the training set.\n",
    "\n",
    "Test your code by building a list of all non-binary columns in your `practice_X_train` and scaling only those columns. Call the result `practice_X_train_scaled`. Display the `.describe()` and verify that you have correctly scaled all columns, including the polynomial columns.\n",
    "\n",
    "**Hint: employ the provided list of binary columns and use `pd.columns.difference()`**\n",
    "\n",
    "`binary_columns = [ 'holiday', 'workingday','Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec', 'spring',\n",
    "       'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
    "       'Cloudy', 'Snow', 'Storm']`\n",
    "\n",
    "\n",
    "**1.4** Write a code to augment your a dataset with higher-order features for `temp`, `atemp`, `hum`,`windspeed`, and `hour`. You should include ONLY the pure powers of these columns. So with degree=2 you should produce `atemp^2` and `hum^2` but not `atemp*hum` or any other two-feature interactions. \n",
    "\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by producing `practice_X_train_poly`, a training dataset with quadratic and cubic features built from `practice_X_train_scaled`, and printing `practice_X_train_poly`'s column names and `.head()`.\n",
    "\n",
    "**1.5** Write code to add interaction terms to the model. Specifically, we want interactions between the continuous predictors (`temp`,`atemp`, `hum`,`windspeed`) and the month and weekday dummies (`Feb`, `Mar`...`Dec`, `Mon`, `Tue`, ... `Sat`). That means you SHOULD build `atemp*Feb` and `hum*Mon` and so on, but NOT `Feb*Mar` and NOT `Feb*Tue`. The interaction terms should always be a continuous feature times a month dummy or a continuous feature times a weekday dummy.\n",
    "\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by adding interaction terms to `practice_X_train_poly` and show its column names and `.head()`**\n",
    "\n",
    "**1.6** Combine all your code so far into a function that takes in `bikes_train`, `bikes_val`, the names of columns for polynomial, the target column, the columns to be dropped and produces computation-ready design matrices `X_train` and `X_val` and responses `y_train` and `y_val`. Your final function should build correct, scaled design matrices with the stated interaction terms and any polynomial degree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Read in the provided `bikes_student.csv` to a data frame named `bikes_main`. Split it into a training set `bikes_train` and a validation set `bikes_val`. Use `random_state=90`, a test set size of .2, and stratify on month. Remember to specify the data's index column as you read it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWIlhxR39wwq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dteday</th>\n",
       "      <th>hour</th>\n",
       "      <th>year</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>...</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Cloudy</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Storm</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>2011-09-07</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10558</th>\n",
       "      <td>2012-03-21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>2012-08-16</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>2011-04-28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.5758</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dteday  hour  year  holiday  workingday  temp   atemp   hum  \\\n",
       "5887   2011-09-07    19     0        0           1  0.64  0.5758  0.89   \n",
       "10558  2012-03-21     1     1        0           1  0.52  0.5000  0.83   \n",
       "14130  2012-08-16    23     1        0           1  0.70  0.6515  0.54   \n",
       "2727   2011-04-28    13     0        0           1  0.62  0.5758  0.83   \n",
       "8716   2012-01-04     0     1        0           1  0.08  0.0606  0.42   \n",
       "\n",
       "       windspeed  casual  ...    Mon  Tue  Wed  Thu  Fri  Sat  Cloudy  Snow  \\\n",
       "5887      0.0000      14  ...      0    0    1    0    0    0       1     0   \n",
       "10558     0.0896       4  ...      0    0    1    0    0    0       0     0   \n",
       "14130     0.1045      58  ...      0    0    0    1    0    0       0     0   \n",
       "2727      0.2985      18  ...      0    0    0    1    0    0       1     0   \n",
       "8716      0.3284       0  ...      0    0    1    0    0    0       0     0   \n",
       "\n",
       "       Storm  month  \n",
       "5887       0      9  \n",
       "10558      0      3  \n",
       "14130      0      8  \n",
       "2727       0      4  \n",
       "8716       0      1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "bikes_main = pd.read_csv('./data/bikes_student.csv', index_col= 0)\n",
    "bikes_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dteday', 'hour', 'year', 'holiday', 'workingday', 'temp', 'atemp',\n",
      "       'hum', 'windspeed', 'casual', 'registered', 'counts', 'Feb', 'Mar',\n",
      "       'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec',\n",
      "       'spring', 'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
      "       'Cloudy', 'Snow', 'Storm', 'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(bikes_main.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_train, bikes_val = train_test_split(bikes_main, test_size = 0.2, stratify = bikes_main.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0YncxWuaW3k"
   },
   "source": [
    "**1.2** As with last homework, the response will be the `counts` column and we'll drop `counts`, `registered` and `casual` for being trivial predictors, drop `workingday` and `month` for being multicolinear with other columns, and `dteday` for being inappropriate for regression. Write code to do this.\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by producing `practice_y_train` and `practice_X_train`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def get_X_and_y(df, response_column, columns_to_drop):\n",
    "    response_column = ['counts']\n",
    "    columns_to_drop = ['counts', 'registered', 'casual','workingday','month','dteday']\n",
    "    \n",
    "    df_X = df.drop(columns_to_drop, axis = 1)\n",
    "    df_y = df[response_column]\n",
    "    \n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_column = ['counts']\n",
    "columns_to_drop = ['counts', 'registered', 'casual','workingday','month','dteday']\n",
    "practice_X_train, practice_y_train = get_X_and_y(bikes_train, response_column, columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hour', 'year', 'holiday', 'temp', 'atemp', 'hum', 'windspeed', 'Feb',\n",
      "       'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec',\n",
      "       'spring', 'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
      "       'Cloudy', 'Snow', 'Storm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(practice_X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['counts'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(practice_y_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mr3zjw-Y48cx"
   },
   "source": [
    "**1.3** Write a function to standardize a provided subset of columns in your training/validation/test sets. Remember that while you will be scaling all of your data, you must learn the scaling parameters (mean and SD) from only the training set.\n",
    "\n",
    "Test your code by building a list of all non-binary columns in your `practice_X_train` and scaling only those columns. Call the result `practice_X_train_scaled`. Display the `.describe()` and verify that you have correctly scaled all columns, including the polynomial columns.\n",
    "\n",
    "**Hint: employ the provided list of binary columns and use `pd.columns.difference()`**\n",
    "\n",
    "`binary_columns = [ 'holiday', 'workingday','Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec', 'spring',\n",
    "       'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
    "       'Cloudy', 'Snow', 'Storm']`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'> WHAT POLYNOMIAL COLUMN?? </FONT>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "pIm1TIqf48c4",
    "outputId": "af5391ee-8a4b-49da-ade4-4e8411fb412e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def scale_col(df_to_scale, df_train, col_to_scale):\n",
    "    #select subsets\n",
    "    df_train = df_train[col_to_scale]\n",
    "    df_to_scale = df_to_scale[col_to_scale]\n",
    "    \n",
    "    #get means and standard dev. for training data\n",
    "    means = df_train.mean()\n",
    "    stds = df_train.std()\n",
    "    \n",
    "    #standardize columns\n",
    "    return (df_to_scale - means)/stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "      <th>hour</th>\n",
       "      <th>hum</th>\n",
       "      <th>temp</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.222489e-15</td>\n",
       "      <td>-5.329071e-17</td>\n",
       "      <td>2.813749e-15</td>\n",
       "      <td>-4.462208e-15</td>\n",
       "      <td>6.590284e-15</td>\n",
       "      <td>-7.105427e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.415738e+00</td>\n",
       "      <td>-1.691610e+00</td>\n",
       "      <td>-3.415218e+00</td>\n",
       "      <td>-2.374607e+00</td>\n",
       "      <td>-1.617293e+00</td>\n",
       "      <td>-1.027889e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.334458e-01</td>\n",
       "      <td>-8.123948e-01</td>\n",
       "      <td>-7.422760e-01</td>\n",
       "      <td>-8.155112e-01</td>\n",
       "      <td>-7.752930e-01</td>\n",
       "      <td>-1.027889e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.560565e-02</td>\n",
       "      <td>6.682035e-02</td>\n",
       "      <td>5.960661e-02</td>\n",
       "      <td>1.600672e-02</td>\n",
       "      <td>-5.415467e-02</td>\n",
       "      <td>9.718949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.370420e-01</td>\n",
       "      <td>7.994997e-01</td>\n",
       "      <td>8.080304e-01</td>\n",
       "      <td>8.475247e-01</td>\n",
       "      <td>6.677894e-01</td>\n",
       "      <td>9.718949e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.507530e+00</td>\n",
       "      <td>1.678715e+00</td>\n",
       "      <td>1.930666e+00</td>\n",
       "      <td>2.302681e+00</td>\n",
       "      <td>5.237147e+00</td>\n",
       "      <td>9.718949e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              atemp          hour           hum          temp     windspeed  \\\n",
       "count  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03   \n",
       "mean   5.222489e-15 -5.329071e-17  2.813749e-15 -4.462208e-15  6.590284e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -2.415738e+00 -1.691610e+00 -3.415218e+00 -2.374607e+00 -1.617293e+00   \n",
       "25%   -8.334458e-01 -8.123948e-01 -7.422760e-01 -8.155112e-01 -7.752930e-01   \n",
       "50%    4.560565e-02  6.682035e-02  5.960661e-02  1.600672e-02 -5.415467e-02   \n",
       "75%    8.370420e-01  7.994997e-01  8.080304e-01  8.475247e-01  6.677894e-01   \n",
       "max    2.507530e+00  1.678715e+00  1.930666e+00  2.302681e+00  5.237147e+00   \n",
       "\n",
       "               year  \n",
       "count  1.000000e+03  \n",
       "mean  -7.105427e-18  \n",
       "std    1.000000e+00  \n",
       "min   -1.027889e+00  \n",
       "25%   -1.027889e+00  \n",
       "50%    9.718949e-01  \n",
       "75%    9.718949e-01  \n",
       "max    9.718949e-01  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns = [ 'holiday', 'workingday','Feb', 'Mar', 'Apr',\n",
    "       'May', 'Jun', 'Jul', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec', 'spring',\n",
    "       'summer', 'fall', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat',\n",
    "       'Cloudy', 'Snow', 'Storm']\n",
    "non_binary_columns = practice_X_train.columns.difference(binary_columns)\n",
    "practice_X_train_scaled  = scale_col(practice_X_train, practice_X_train, non_binary_columns)\n",
    "practice_X_train_scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zEBl-5bU48ci"
   },
   "source": [
    "**1.4** Write a code to augment your a dataset with higher-order features for `temp`, `atemp`, `hum`,`windspeed`, and `hour`. You should include ONLY pure powers of these columns. So with degree=2 you should produce `atemp^2` and `hum^2` but not `atemp*hum` or any other two-feature interactions. \n",
    "\n",
    "\n",
    "Encapsulate this process as a function with apropriate inputs and outputs, and test your code by producing `practice_X_train_poly`, a training dataset with qudratic and cubic features built from `practice_X_train_scaled`, and printing `practice_X_train_poly`'s column names and `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "UXgj9yxu48cj",
    "outputId": "d1e9e4f7-41ab-4cae-a900-e11e0890638e"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def add_poly_columns(df, columns, degree):\n",
    "    \"\"\"\n",
    "    df pandas DataFrame: the df to add polynomial terms to\n",
    "    columns list(str): the list of columns for which to add polynomial terms\n",
    "    degree int: add polynomials from 2 to this degree (inclusive). Interactions are not included.\n",
    "    \"\"\"\n",
    "    df_poly = df.copy()\n",
    "    for d in range(2, degree + 1):\n",
    "        for col in columns:\n",
    "            df_poly[col+'^'+str(d)] = df[col].apply(lambda x : x**d)\n",
    "    return df_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "      <th>hour</th>\n",
       "      <th>hum</th>\n",
       "      <th>temp</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>year</th>\n",
       "      <th>atemp^2</th>\n",
       "      <th>hour^2</th>\n",
       "      <th>hum^2</th>\n",
       "      <th>temp^2</th>\n",
       "      <th>windspeed^2</th>\n",
       "      <th>year^2</th>\n",
       "      <th>atemp^3</th>\n",
       "      <th>hour^3</th>\n",
       "      <th>hum^3</th>\n",
       "      <th>temp^3</th>\n",
       "      <th>windspeed^3</th>\n",
       "      <th>year^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10090</th>\n",
       "      <td>0.309611</td>\n",
       "      <td>0.066820</td>\n",
       "      <td>-1.437241</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>0.186762</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>0.095859</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>2.065661</td>\n",
       "      <td>0.107470</td>\n",
       "      <td>0.034880</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>0.029679</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>-2.968853</td>\n",
       "      <td>0.035231</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.918032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>-0.393630</td>\n",
       "      <td>-0.372787</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>-0.503692</td>\n",
       "      <td>0.787845</td>\n",
       "      <td>-1.027889</td>\n",
       "      <td>0.154945</td>\n",
       "      <td>0.138970</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.253706</td>\n",
       "      <td>0.620699</td>\n",
       "      <td>1.056556</td>\n",
       "      <td>-0.060991</td>\n",
       "      <td>-0.051806</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>0.489015</td>\n",
       "      <td>-1.086022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>-1.360877</td>\n",
       "      <td>1.678715</td>\n",
       "      <td>-0.421523</td>\n",
       "      <td>-1.231270</td>\n",
       "      <td>0.426873</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>1.851985</td>\n",
       "      <td>2.818083</td>\n",
       "      <td>0.177682</td>\n",
       "      <td>1.516026</td>\n",
       "      <td>0.182220</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>-2.520323</td>\n",
       "      <td>4.730759</td>\n",
       "      <td>-0.074897</td>\n",
       "      <td>-1.866638</td>\n",
       "      <td>0.077785</td>\n",
       "      <td>0.918032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>-0.393630</td>\n",
       "      <td>-1.105467</td>\n",
       "      <td>1.930666</td>\n",
       "      <td>-0.503692</td>\n",
       "      <td>0.787845</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>0.154945</td>\n",
       "      <td>1.222056</td>\n",
       "      <td>3.727471</td>\n",
       "      <td>0.253706</td>\n",
       "      <td>0.620699</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>-0.060991</td>\n",
       "      <td>-1.350942</td>\n",
       "      <td>7.196502</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>0.489015</td>\n",
       "      <td>0.918032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>-1.185066</td>\n",
       "      <td>-1.691610</td>\n",
       "      <td>0.326901</td>\n",
       "      <td>-1.231270</td>\n",
       "      <td>-0.775293</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>1.404382</td>\n",
       "      <td>2.861544</td>\n",
       "      <td>0.106864</td>\n",
       "      <td>1.516026</td>\n",
       "      <td>0.601079</td>\n",
       "      <td>0.944580</td>\n",
       "      <td>-1.664286</td>\n",
       "      <td>-4.840617</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>-1.866638</td>\n",
       "      <td>-0.466013</td>\n",
       "      <td>0.918032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          atemp      hour       hum      temp  windspeed      year   atemp^2  \\\n",
       "10090  0.309611  0.066820 -1.437241  0.327826   0.186762  0.971895  0.095859   \n",
       "8441  -0.393630 -0.372787  0.113065 -0.503692   0.787845 -1.027889  0.154945   \n",
       "8835  -1.360877  1.678715 -0.421523 -1.231270   0.426873  0.971895  1.851985   \n",
       "9270  -0.393630 -1.105467  1.930666 -0.503692   0.787845  0.971895  0.154945   \n",
       "9458  -1.185066 -1.691610  0.326901 -1.231270  -0.775293  0.971895  1.404382   \n",
       "\n",
       "         hour^2     hum^2    temp^2  windspeed^2    year^2   atemp^3  \\\n",
       "10090  0.004465  2.065661  0.107470     0.034880  0.944580  0.029679   \n",
       "8441   0.138970  0.012784  0.253706     0.620699  1.056556 -0.060991   \n",
       "8835   2.818083  0.177682  1.516026     0.182220  0.944580 -2.520323   \n",
       "9270   1.222056  3.727471  0.253706     0.620699  0.944580 -0.060991   \n",
       "9458   2.861544  0.106864  1.516026     0.601079  0.944580 -1.664286   \n",
       "\n",
       "         hour^3     hum^3    temp^3  windspeed^3    year^3  \n",
       "10090  0.000298 -2.968853  0.035231     0.006514  0.918032  \n",
       "8441  -0.051806  0.001445 -0.127790     0.489015 -1.086022  \n",
       "8835   4.730759 -0.074897 -1.866638     0.077785  0.918032  \n",
       "9270  -1.350942  7.196502 -0.127790     0.489015  0.918032  \n",
       "9458  -4.840617  0.034934 -1.866638    -0.466013  0.918032  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = practice_X_train_scaled.columns\n",
    "practice_X_train_poly = add_poly_columns(practice_X_train_scaled, columns, 3)\n",
    "practice_X_train_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['atemp', 'hour', 'hum', 'temp', 'windspeed', 'year', 'atemp^2',\n",
      "       'hour^2', 'hum^2', 'temp^2', 'windspeed^2', 'year^2', 'atemp^3',\n",
      "       'hour^3', 'hum^3', 'temp^3', 'windspeed^3', 'year^3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(practice_X_train_poly.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pK5Mhlqc48dG"
   },
   "source": [
    "**1.5** Write code to add interaction terms to the model. Specifically, we want interactions between the continuous predictors (`temp`,`atemp`, `hum`,`windspeed`) and the month and weekday dummies (`Feb`, `Mar`...`Dec`, `Mon`, `Tue`, ... `Sat`). That means you SHOULD build `atemp*Feb` and `hum*Mon` and so on, but NOT `Feb*Mar` and NOT `Feb*Tue`. The interaction terms should always be a continuous feature times a month dummy or a continuous feature times a weekday dummy. <font color = 'red'> **CHECK THIS** </font>\n",
    "\n",
    "\n",
    "Encapsulate this process as a function with appropriate inputs and outputs, and test your code by adding interaction terms to `practice_X_train_poly` and show its column names and `.head()`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gB6wlgj948dP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def add_interaction_terms(df_to_add_interactions,\n",
    "                          df_original,\n",
    "                          continuous_columns = ['temp','atemp','hum','windspeed'],\n",
    "                          dummy_columns = ['Feb', 'Mar', 'Apr','May', 'Jun', 'Jul',\n",
    "                                           'Aug', 'Sept', 'Oct', 'Nov', 'Dec','Mon', \n",
    "                                           'Tue', 'Wed', 'Thu', 'Fri', 'Sat']):\n",
    "    \"\"\"\n",
    "    df_to_add_interactions pandas DataFrame: dataframe to add interaction terms\n",
    "    df_original pandas DataFrame: dataframe holding the terms to form interactions with\n",
    "    continuous_columns list(str): names of continuous predictors\n",
    "    dummy_columns: names of dummy predictors (0/1)\n",
    "    \"\"\"\n",
    "    df_interact = df_to_add_interactions.copy()\n",
    "    for cont_col in continuous_columns:\n",
    "        for other_col in dummy_columns:\n",
    "            if cont_col is not other_col:\n",
    "                df_interact[cont_col+\"*\"+other_col] = df_original[cont_col]*df_original[other_col]\n",
    "    return df_interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_X_train_interact = add_interaction_terms(practice_X_train_poly, practice_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['atemp', 'hour', 'hum', 'temp', 'windspeed', 'year', 'atemp^2',\n",
       "       'hour^2', 'hum^2', 'temp^2', 'windspeed^2', 'year^2', 'atemp^3',\n",
       "       'hour^3', 'hum^3', 'temp^3', 'windspeed^3', 'year^3', 'temp*Feb',\n",
       "       'temp*Mar', 'temp*Apr', 'temp*May', 'temp*Jun', 'temp*Jul', 'temp*Aug',\n",
       "       'temp*Sept', 'temp*Oct', 'temp*Nov', 'temp*Dec', 'temp*Mon', 'temp*Tue',\n",
       "       'temp*Wed', 'temp*Thu', 'temp*Fri', 'temp*Sat', 'atemp*Feb',\n",
       "       'atemp*Mar', 'atemp*Apr', 'atemp*May', 'atemp*Jun', 'atemp*Jul',\n",
       "       'atemp*Aug', 'atemp*Sept', 'atemp*Oct', 'atemp*Nov', 'atemp*Dec',\n",
       "       'atemp*Mon', 'atemp*Tue', 'atemp*Wed', 'atemp*Thu', 'atemp*Fri',\n",
       "       'atemp*Sat', 'hum*Feb', 'hum*Mar', 'hum*Apr', 'hum*May', 'hum*Jun',\n",
       "       'hum*Jul', 'hum*Aug', 'hum*Sept', 'hum*Oct', 'hum*Nov', 'hum*Dec',\n",
       "       'hum*Mon', 'hum*Tue', 'hum*Wed', 'hum*Thu', 'hum*Fri', 'hum*Sat',\n",
       "       'windspeed*Feb', 'windspeed*Mar', 'windspeed*Apr', 'windspeed*May',\n",
       "       'windspeed*Jun', 'windspeed*Jul', 'windspeed*Aug', 'windspeed*Sept',\n",
       "       'windspeed*Oct', 'windspeed*Nov', 'windspeed*Dec', 'windspeed*Mon',\n",
       "       'windspeed*Tue', 'windspeed*Wed', 'windspeed*Thu', 'windspeed*Fri',\n",
       "       'windspeed*Sat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_X_train_interact.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atemp</th>\n",
       "      <th>hour</th>\n",
       "      <th>hum</th>\n",
       "      <th>temp</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>year</th>\n",
       "      <th>atemp^2</th>\n",
       "      <th>hour^2</th>\n",
       "      <th>hum^2</th>\n",
       "      <th>temp^2</th>\n",
       "      <th>...</th>\n",
       "      <th>windspeed*Sept</th>\n",
       "      <th>windspeed*Oct</th>\n",
       "      <th>windspeed*Nov</th>\n",
       "      <th>windspeed*Dec</th>\n",
       "      <th>windspeed*Mon</th>\n",
       "      <th>windspeed*Tue</th>\n",
       "      <th>windspeed*Wed</th>\n",
       "      <th>windspeed*Thu</th>\n",
       "      <th>windspeed*Fri</th>\n",
       "      <th>windspeed*Sat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10090</th>\n",
       "      <td>0.309611</td>\n",
       "      <td>0.066820</td>\n",
       "      <td>-1.437241</td>\n",
       "      <td>0.327826</td>\n",
       "      <td>0.186762</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>0.095859</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>2.065661</td>\n",
       "      <td>0.107470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8441</th>\n",
       "      <td>-0.393630</td>\n",
       "      <td>-0.372787</td>\n",
       "      <td>0.113065</td>\n",
       "      <td>-0.503692</td>\n",
       "      <td>0.787845</td>\n",
       "      <td>-1.027889</td>\n",
       "      <td>0.154945</td>\n",
       "      <td>0.138970</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.253706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835</th>\n",
       "      <td>-1.360877</td>\n",
       "      <td>1.678715</td>\n",
       "      <td>-0.421523</td>\n",
       "      <td>-1.231270</td>\n",
       "      <td>0.426873</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>1.851985</td>\n",
       "      <td>2.818083</td>\n",
       "      <td>0.177682</td>\n",
       "      <td>1.516026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>-0.393630</td>\n",
       "      <td>-1.105467</td>\n",
       "      <td>1.930666</td>\n",
       "      <td>-0.503692</td>\n",
       "      <td>0.787845</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>0.154945</td>\n",
       "      <td>1.222056</td>\n",
       "      <td>3.727471</td>\n",
       "      <td>0.253706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>-1.185066</td>\n",
       "      <td>-1.691610</td>\n",
       "      <td>0.326901</td>\n",
       "      <td>-1.231270</td>\n",
       "      <td>-0.775293</td>\n",
       "      <td>0.971895</td>\n",
       "      <td>1.404382</td>\n",
       "      <td>2.861544</td>\n",
       "      <td>0.106864</td>\n",
       "      <td>1.516026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          atemp      hour       hum      temp  windspeed      year   atemp^2  \\\n",
       "10090  0.309611  0.066820 -1.437241  0.327826   0.186762  0.971895  0.095859   \n",
       "8441  -0.393630 -0.372787  0.113065 -0.503692   0.787845 -1.027889  0.154945   \n",
       "8835  -1.360877  1.678715 -0.421523 -1.231270   0.426873  0.971895  1.851985   \n",
       "9270  -0.393630 -1.105467  1.930666 -0.503692   0.787845  0.971895  0.154945   \n",
       "9458  -1.185066 -1.691610  0.326901 -1.231270  -0.775293  0.971895  1.404382   \n",
       "\n",
       "         hour^2     hum^2    temp^2      ...        windspeed*Sept  \\\n",
       "10090  0.004465  2.065661  0.107470      ...                   0.0   \n",
       "8441   0.138970  0.012784  0.253706      ...                   0.0   \n",
       "8835   2.818083  0.177682  1.516026      ...                   0.0   \n",
       "9270   1.222056  3.727471  0.253706      ...                   0.0   \n",
       "9458   2.861544  0.106864  1.516026      ...                   0.0   \n",
       "\n",
       "       windspeed*Oct  windspeed*Nov  windspeed*Dec  windspeed*Mon  \\\n",
       "10090            0.0            0.0         0.0000            0.0   \n",
       "8441             0.0            0.0         0.2985            0.0   \n",
       "8835             0.0            0.0         0.0000            0.0   \n",
       "9270             0.0            0.0         0.0000            0.0   \n",
       "9458             0.0            0.0         0.0000            0.0   \n",
       "\n",
       "       windspeed*Tue  windspeed*Wed  windspeed*Thu  windspeed*Fri  \\\n",
       "10090            0.0            0.0         0.2239         0.0000   \n",
       "8441             0.0            0.0         0.0000         0.2985   \n",
       "8835             0.0            0.0         0.0000         0.0000   \n",
       "9270             0.0            0.0         0.0000         0.2985   \n",
       "9458             0.0            0.0         0.0000         0.0000   \n",
       "\n",
       "       windspeed*Sat  \n",
       "10090         0.0000  \n",
       "8441          0.0000  \n",
       "8835          0.0000  \n",
       "9270          0.0000  \n",
       "9458          0.1045  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "practice_X_train_interact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGd5qdPu48da"
   },
   "source": [
    "**1.6** Combine all your code so far into a function that takes in `bikes_train`, `bikes_val`, the names of columns for polynomial, the target column, the columns to be dropped and produces computation-ready design matrices `X_train` and `X_val` and responses `y_train` and `y_val`. Your final function should build correct, scaled design matrices with the stated interaction terms and any polynomial degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'> **WHICH COLUMNS FOR SCALING? ARE THESE THE ONLY ONE DEGREE TERMS?** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_design_mats(train_df, val_df,  degree, \n",
    "                    columns_forpoly=['temp', 'atemp', 'hum','windspeed', 'hour'],\n",
    "                    target_col='counts', \n",
    "                    bad_columns=['counts', 'registered', 'casual', 'workingday', 'month', 'dteday']):\n",
    "    # add code here \n",
    "    \n",
    "    # get predictors and target\n",
    "    x_val,y_val = get_X_and_y(train_df, target_col, bad_columns)\n",
    "    x_train,y_train = get_X_and_y(train_df, target_col, bad_columns)\n",
    "    \n",
    "    # scale columns\n",
    "    x_val_scaled = scale_col(x_val, x_train, columns_forpoly)\n",
    "    x_train_scaled = scale_col(x_train, x_train, columns_forpoly)\n",
    "    \n",
    "    # add polynomial terms\n",
    "    x_val_poly = add_poly_columns(x_val_scaled, columns_forpoly, degree)\n",
    "    x_train_poly = add_poly_columns(x_train_scaled, columns_forpoly, degree)\n",
    "    \n",
    "    # add interaction terms\n",
    "    x_val_interact = add_interaction_terms(x_val_poly, x_val)\n",
    "    x_train_interact = add_interaction_terms(x_train_poly, x_train)\n",
    "    \n",
    "    x_train, x_val = x_train_interact, x_val_interact\n",
    "    \n",
    "    return x_train,y_train, x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "x_train,y_train, x_val,y_val = get_design_mats(bikes_train, bikes_val,  3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'atemp', 'hum', 'windspeed', 'hour', 'temp^2', 'atemp^2',\n",
       "       'hum^2', 'windspeed^2', 'hour^2', 'temp^3', 'atemp^3', 'hum^3',\n",
       "       'windspeed^3', 'hour^3', 'temp*Feb', 'temp*Mar', 'temp*Apr', 'temp*May',\n",
       "       'temp*Jun', 'temp*Jul', 'temp*Aug', 'temp*Sept', 'temp*Oct', 'temp*Nov',\n",
       "       'temp*Dec', 'temp*Mon', 'temp*Tue', 'temp*Wed', 'temp*Thu', 'temp*Fri',\n",
       "       'temp*Sat', 'atemp*Feb', 'atemp*Mar', 'atemp*Apr', 'atemp*May',\n",
       "       'atemp*Jun', 'atemp*Jul', 'atemp*Aug', 'atemp*Sept', 'atemp*Oct',\n",
       "       'atemp*Nov', 'atemp*Dec', 'atemp*Mon', 'atemp*Tue', 'atemp*Wed',\n",
       "       'atemp*Thu', 'atemp*Fri', 'atemp*Sat', 'hum*Feb', 'hum*Mar', 'hum*Apr',\n",
       "       'hum*May', 'hum*Jun', 'hum*Jul', 'hum*Aug', 'hum*Sept', 'hum*Oct',\n",
       "       'hum*Nov', 'hum*Dec', 'hum*Mon', 'hum*Tue', 'hum*Wed', 'hum*Thu',\n",
       "       'hum*Fri', 'hum*Sat', 'windspeed*Feb', 'windspeed*Mar', 'windspeed*Apr',\n",
       "       'windspeed*May', 'windspeed*Jun', 'windspeed*Jul', 'windspeed*Aug',\n",
       "       'windspeed*Sept', 'windspeed*Oct', 'windspeed*Nov', 'windspeed*Dec',\n",
       "       'windspeed*Mon', 'windspeed*Tue', 'windspeed*Wed', 'windspeed*Thu',\n",
       "       'windspeed*Fri', 'windspeed*Sat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['counts'], dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['temp', 'atemp', 'hum', 'windspeed', 'hour', 'temp^2', 'atemp^2',\n",
       "       'hum^2', 'windspeed^2', 'hour^2', 'temp^3', 'atemp^3', 'hum^3',\n",
       "       'windspeed^3', 'hour^3', 'temp*atemp', 'temp*hum', 'temp*windspeed',\n",
       "       'temp*Feb', 'temp*Mar', 'temp*Apr', 'temp*May', 'temp*Jun', 'temp*Jul',\n",
       "       'temp*Aug', 'temp*Sept', 'temp*Oct', 'temp*Nov', 'temp*Dec', 'temp*Mon',\n",
       "       'temp*Tue', 'temp*Wed', 'temp*Thu', 'temp*Fri', 'temp*Sat',\n",
       "       'atemp*temp', 'atemp*hum', 'atemp*windspeed', 'atemp*Feb', 'atemp*Mar',\n",
       "       'atemp*Apr', 'atemp*May', 'atemp*Jun', 'atemp*Jul', 'atemp*Aug',\n",
       "       'atemp*Sept', 'atemp*Oct', 'atemp*Nov', 'atemp*Dec', 'atemp*Mon',\n",
       "       'atemp*Tue', 'atemp*Wed', 'atemp*Thu', 'atemp*Fri', 'atemp*Sat',\n",
       "       'hum*temp', 'hum*atemp', 'hum*windspeed', 'hum*Feb', 'hum*Mar',\n",
       "       'hum*Apr', 'hum*May', 'hum*Jun', 'hum*Jul', 'hum*Aug', 'hum*Sept',\n",
       "       'hum*Oct', 'hum*Nov', 'hum*Dec', 'hum*Mon', 'hum*Tue', 'hum*Wed',\n",
       "       'hum*Thu', 'hum*Fri', 'hum*Sat', 'windspeed*temp', 'windspeed*atemp',\n",
       "       'windspeed*hum', 'windspeed*Feb', 'windspeed*Mar', 'windspeed*Apr',\n",
       "       'windspeed*May', 'windspeed*Jun', 'windspeed*Jul', 'windspeed*Aug',\n",
       "       'windspeed*Sept', 'windspeed*Oct', 'windspeed*Nov', 'windspeed*Dec',\n",
       "       'windspeed*Mon', 'windspeed*Tue', 'windspeed*Wed', 'windspeed*Thu',\n",
       "       'windspeed*Fri', 'windspeed*Sat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['counts'], dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 2 [20pts]: Regularization via Ridge </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** For each degree in 1 through 8:\n",
    "\n",
    "1.  Build the training design matrix and validation design matrix using the function `get_design_mats` with polynomial terms up through the specified degree.\n",
    "\n",
    "2.  Fit a regression model to the training data.\n",
    "\n",
    "3.  Report the model's score on the validation data.\n",
    "\n",
    "**2.2** Discuss patterns you see in the results from 2.1. Which model would you select, and why?\n",
    "\n",
    "**2.3** Let's try regularizing our models via ridge regression. Build a table showing the validation set $R^2$ of polynomial models with degree from 1-8, regularized at the levels $\\lambda = (.01, .05, .1,.5, 1, 5, 10, 50, 100)$. Do not perform cross validation at this point, simply report performance on the single validation set. \n",
    "\n",
    "**2.4** Find the best-scoring degree and regularization combination.\n",
    "\n",
    "**2.5** It's time to see how well our selected model will do on future data. Read in the provided test dataset, do any required formatting, and report the best model's $R^2$ score. How does it compare to the validation set score that made us choose this model? \n",
    "\n",
    "**2.6** Why do you think our model's test score was quite a bit worse than its validation score? Does the test set simply contain harder examples, or is something else going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** For each degree in 1 through 8:\n",
    "\n",
    "1.  Build the training design matrix and validation design matrix using the function `get_design_mats` with polynomial terms up through the specified degree.\n",
    "\n",
    "2.  Fit a regression model to the training data.\n",
    "\n",
    "3.  Report the model's score on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "VTWx4demHUo0",
    "outputId": "fb9ca7f7-8b7b-42e5-fab8-471ab5f57180"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Discuss patterns you see in the results from 2.1. Which model would you select, and why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQJ1vesGNwOf"
   },
   "source": [
    "**2.3** Let's try regularizing our models via ridge regression. Build a table showing the validation set $R^2$ of polynomial models with degree from 1-8, regularized at the levels $\\lambda = (.01, .05, .1,.5, 1, 5, 10, 50, 100)$. Do not perform cross validation at this point, simply report performance on the single validation set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "GUvYAWHzQAmb",
    "outputId": "7a60ee39-ee8e-46a9-aff7-781580b83717"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TBwFV1wCTWnw"
   },
   "source": [
    "**2.4** Find the best-scoring degree and regularization combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "1zminoljTm9y",
    "outputId": "b12035c4-5a20-4449-fed4-dcc5e81c0db9"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KU3rqk4qU5BK"
   },
   "source": [
    "**2.5** It's time to see how well our selected model will do on future data. Read in the provided test dataset `data/bikes_test.csv`, do any required formatting, and report the best model's $R^2$ score. How does it compare to the validation set score that made us choose this model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cbzfV7HaW_U1"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFjeBDXIW7nE"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6** Why do you think our model's test score was quite a bit worse than its validation score? Does the test set simply contain harder examples, or is something else going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 3 [20pts]: Comparing Ridge, Lasso, and OLS </b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Build a dataset with polynomial degree 1 and fit an OLS model, a Ridge model, and a Lasso model. Use `RidgeCV` and `LassoCV` to select the best regularization level from among `(.1,.5,1,5,10,50,100)`. \n",
    "\n",
    "Note: On the lasso model, you will need to increase `max_iter` to 100,000 for the optimization to converge.\n",
    "\n",
    "**3.2** Plot histograms of the coefficients found by each of OLS, ridge, and lasso. What trends do you see in the magnitude of the coefficients?\n",
    "\n",
    "**3.3** The plots above show the overall distribution of coefficient values in each model, but do not show how each model treats individual coefficients. Build a plot which cleanly presents, for each feature in the data, 1) The coefficient assigned by OLS, 2) the coefficient assigned by ridge, and 3) the coefficient assigned by lasso.\n",
    "\n",
    "**Hint: Bar plots are a possible choice, but you are not required to use them**\n",
    "\n",
    "**Hint: use `xticks` to label coefficients with their feature names**\n",
    "\n",
    "**3.4** What trends do you see in the plot above? How do the three approaches handle the correlated pair `temp` and `atemp`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Build a dataset with polynomial degree 1 and fit an OLS model, a Ridge model, and a Lasso model. Use `RidgeCV` and `LassoCV` to select the best regularization level from among `(.1,.5,1,5,10,50,100)`. \n",
    "\n",
    "Note: On the lasso model, you will need to increase `max_iter` to 100,000 for the optimization to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3.2** Plot histograms of the coefficients found by each of OLS, ridge, and lasso. What trends do you see in the magnitude of the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** The plots above show the overall distribution of coefficient values in each model, but do not show how each model treats individual coefficients. Build a plot which cleanly presents, for each feature in the data, 1) The coefficient assigned by OLS, 2) the coefficient assigned by ridge, and 3) the coefficient assigned by lasso.\n",
    "\n",
    "**Hint: Bar plots are a possible choice, but you are not required to use them**\n",
    "\n",
    "**Hint: use `xticks` to label coefficients with their feature names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** What trends do you see in the plot above? How do the three approaches handle the correlated pair `temp` and `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 4 [20 pts]: Reflection </b></div>\n",
    "These problems are open-ended, and you are not expected to write more than 2-3 sentences. We are interested in seeing that you have thought about these issues; you will be graded on how well you justify your conclusions here, not on what you conclude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Reflect back on the `get_design_mats` function you built. Writing this function useful in your analysis? What issues might you have encountered if you copy/pasted the model-building code instead of tying it together in a function? Does a `get_design_mat` function seem wise in general, or are there better options?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** What are the costs and benefits of applying ridge/lasso regularization to an overfit OLS model, versus setting a specific degree of polynomial or forward selecting features for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 4.3** This pset posed a purely predictive goal: forecast ridership as accurately as possible. How important is interpretability in this context? Considering, e.g., your lasso and ridge models from Question 3, how would you react if the models predicted well, but the coefficient values didn't make sense once interpreted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**4.4** Reflect back on our original goal of helping BikeShare predict what demand will be like in the week ahead, and thus how many bikes they can bring in for maintenance. In your view, did we accomplish this goal? If yes, which model would you put into production and why? If not, which model came closest, what other analyses might you conduct, and how likely do you think they are to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "day_level_test.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
