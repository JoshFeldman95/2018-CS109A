{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "## Homework 2  AC 209 : Linear and k-NN Regression\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- If you submit individually and you have worked with someone, please include the name of your [one] partner below. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of people you have worked with goes here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "\n",
    "<div class='theme'>Linear Algebra, Accuracy, and Confidence Intervals </div>\n",
    "In this part of the homework, you will see how _uncertainty_ in the beta coefficients can directly impact our ability to make predictions with a linear regression model and how in general we can do inference on the predictors. You will explore a linear-algebra formula that tells us how accurately we've learned the beta parameters, going beyond simple SEs to describe the joint distribution of the betas. You'll see that the structure of the $X$ data can strongly impact how well we can learn the betas, and you'll determine desirable prroperties of the $X$ data.\n",
    "\n",
    "The data for this supplement are the same as in lab1, and are imported for you in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"data/cleaned_mtcars.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['mpg']].values\n",
    "X = df[['cyl','disp','hp','wt','qsec']]\n",
    "\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 5 [4 pts] </b> </div>\n",
    "\n",
    "**5.1** Fit a simple linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our prediction at various values of `disp` and make a well-labeled plot showing\n",
    " 1. The observed values of `disp` and `mpg`.\n",
    " 2. The regression line.\n",
    " 3. The upper and lower bounds of the 95% confidence interval for the _predicted_ (not the observed) `mpg` at any given displacement.\n",
    " \n",
    "**5.2** Why do we have a confidence interval for our predicted value? Why isn't the prediction just a single number?\n",
    "\n",
    "**5.3** Someone asks what `mpg` you would predict for a `disp` value of 400. What do you tell them? paying attention to the confidence interval (5.1.3) above?\n",
    "\n",
    "**5.4** Why does the 95% confidence interval for the predicted `mpg` appear to curve as we move away from the data's center? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Fit a linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our prediction at various levels of `disp` and make a well-labled plot showing**\n",
    " 1. **The observed values of weight and mpg**\n",
    " 2. **The regression line**\n",
    " 3. **The upper and lower bounds of the 95% confidence interval for the _mean/predicted mpg_ at any given displacement**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.005436</td>\n",
       "      <td>0.664391</td>\n",
       "      <td>21.648568</td>\n",
       "      <td>24.362303</td>\n",
       "      <td>16.227868</td>\n",
       "      <td>29.783003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.005436</td>\n",
       "      <td>0.664391</td>\n",
       "      <td>21.648568</td>\n",
       "      <td>24.362303</td>\n",
       "      <td>16.227868</td>\n",
       "      <td>29.783003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.148622</td>\n",
       "      <td>0.815316</td>\n",
       "      <td>23.483523</td>\n",
       "      <td>26.813720</td>\n",
       "      <td>18.302683</td>\n",
       "      <td>31.994561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.966354</td>\n",
       "      <td>0.588977</td>\n",
       "      <td>17.763503</td>\n",
       "      <td>20.169205</td>\n",
       "      <td>12.217933</td>\n",
       "      <td>25.714774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.762412</td>\n",
       "      <td>0.837509</td>\n",
       "      <td>13.051990</td>\n",
       "      <td>16.472833</td>\n",
       "      <td>7.905308</td>\n",
       "      <td>21.619515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  23.005436  0.664391      21.648568      24.362303     16.227868   \n",
       "1  23.005436  0.664391      21.648568      24.362303     16.227868   \n",
       "2  25.148622  0.815316      23.483523      26.813720     18.302683   \n",
       "3  18.966354  0.588977      17.763503      20.169205     12.217933   \n",
       "4  14.762412  0.837509      13.051990      16.472833      7.905308   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0     29.783003  \n",
       "1     29.783003  \n",
       "2     31.994561  \n",
       "3     25.714774  \n",
       "4     21.619515  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here \n",
    "model = OLS(y, X[['disp','const']]).fit()\n",
    "summary = model.get_prediction().summary_frame()\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c174ea550>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcjWX/wPHP1xhm7BFiLCMksu+lIhFFJYTSqn5aHqmUnkFKqoc2KnlalNImQvREJCJLkZA1sgwZso91MMv1++O6x8yYc2Y5c7aZ832/XvPqnOs+576vuU3ne67te4kxBqWUUqGrUKAroJRSKrA0ECilVIjTQKCUUiFOA4FSSoU4DQRKKRXiNBAopVSI00CgQo6IfCIiLzmPrxGRLQGqRzUROSkiYVm8xohILX/WS4UeDQQqpBljlhhj6gTo2ruNMSWMMckAIrJIRB709HwiUlRExorIXhE5KiL/FZHwdMcXicgZJ/icTB8ARaSRiGwUkUMi8mS68nARWSEiVbO5dhERGSEif4nIKRGJFZGJIhLtjd9N+ZYGAqUKjhigOVAfuAxoCjx7wWsGOMGnxAUBcBTwNNAIeFZELnHKBwHTjTF/Z3PtacAtwJ1Aaec8vwPX5+H3UX6igUBl4nybGywi65xvdx+JSEUR+V5ETojIjyJykfPaaKf7or/zTXSfiDyV7lyRIjLJ+Ya6WUSeEZE9bq77noi8fkHZLBEZ5Dz+t4jEOXXYIiI5+pARkSYistp53xQgIt2xdunr4+4azrfdaSIyxTm2WkQaubneCyIyznkc7tzDV9PdjzMiclG6e1dYRF4GrgHecb6tv5PulB2cb9pHRWS8iIibX/Vm4G1jzBFjzEHgbaBfTu4RUANYaIyJA/4CqolINaAHMDarN4pIB6AjcKsx5jdjTJIx5pgxZrwx5qMcXl8FkAYC5U4P7P/cl2E/YL4HhgIXY/9uBl7w+uuA2sANQIzz4QDwPBANXOqc764srvkl0Dv1g84JNjcAX4lIHWAA0MIYUxLoBMRm90uISBFgJvAZUBb42vndXL02u2vc6ry/rFPXmem7XtJZDLRzHrcA/gHaOs+vBLYYY46mf4MxZhiwhLRv7APSHe7qnKcR0Mupl8tfwflJ/7yKiJROVzbK6f5ZJiLt0pVvAG4QkSrYf6/t2EDyjDEm0c31UnUAVuag1aCClAYC5c44Y8x+5xviEmCFMWaNMeYs8A3Q5ILXv2CMOWWMWQ98DNzhlPcC/mOMOWqM2YP9cHFnCWCw34wBegK/GGP2AslAUaCeiIQbY2KNMdtz8Hu0BsKBN40xicaYacBvbl6b3TV+N8ZMcz4Yx2BbFq1dnOcXoLaIlAOuBT4CokSkBDYgLM5BvdMbbYyJN8bsBn4CGrt53ffA4yJS3unaSQ3WxZz//hsbkKOAD4D/iUhN59jTwCPAt8CTQBvgBLDDaZUtFpHb3Vy3HLAvl7+TCiIaCJQ7+9M9TnDxvMQFr0//bXAXUNl5XPmCY26/NRqbAfEr0oLIncAXzrFtwBPACOCAiHwlIpVdnecClYE4kzG74i4318/uGn+ne20KsIe03zP9eRKAVdgP/WuxH/zLsR+ungSCf9I9Pk3me5/qZWANsNa53kwgETjg1GuFMeaEMeasMWYSsAy4yTm2yxhzkzGmKTALGIkNDq8DU7D9/2NEpKyL6x4GKuXyd1JBRAOB8pb0s0qqAXudx/uAKm5e58pkoKeIVAdaAdNTDxhjvjTGXA1Ux7YcXslBvfZhv42n7zKp5u7F2VzjfN1FpBD299qLa4uB9tiW02/O805AS+Bnd5fP8jfJhjEmwRgzwBgTZYy5FPsB/XvqrCQ313M13vAc8KExZj/QAFhljDmGDXyuprL+CLR0upVUPqSBQHnLcBEpJiJXAPdjv0UCTAWGOIOjUdg+eLeMMWuAg8CHwDxjTDzY/nsRaS8iRYEz2FaJuw+49H4BkoCBzqBsd+yHcSY5uEYzEekuIoWxLYezwK9urrsYuAfYZIw5BywCHgR2OgO5ruzHdt14RESiRKSyWK2B4dgxGkSkjIh0EpEI5z70xbZW5l1wjnrY8Y13naKdQHsRqYgdA9p94XWNMT8C84FvRKSZc/6SIvKwiOR0sFoFkAYC5S2LgW3AAuB1Y8wPTvlI7DfJndhvjtOwH6BZmYwdgPwyXVlRYDRwCNtVUgE7eI2I9BWRja5O5HwIdwfuA44CvYEZbq7r9hqOWc77jwJ3A92zGEhdDkSS9u1/Eza4uGsNALyFbQ0dFZGsxlLcqelc9xQwCYhJ9+8QDryEDbKHgMeAbsaYCxfTjQceT9eKGIIda9iIHev5B9d6AnOwXwCOYQefm2P/zVWQE92YRuWF2AVDO4FwY0xSDl7/CNDHGNM2u9cGExEZAdQyxmQ160mpfElbBMqnRKSSiLQRkULO9MynsLOOlFJBonCgK6AKvCLA+9gFS/HYWUH/DWiNlFIZaNeQUkqFOJ91DTmzE1aKyB9ik1m94JR/IiI7RWSt8+NucYxSSik/8GXX0FmgvTHmpLMMf6mIfO8cG+ys8MyRiy++2ERHR/uijkopVWD9/vvvh4wx5bN7nc8CgbOS86TzNNz58agfKjo6mlWrVnmrakopFRJExOUq+gv5dNaQiISJyFrsEvf5xpgVzqGXxWa2HOss3nH13v4iskpEVh086G79jVJKqbzyaSAwxiQbYxpjl+K3FJH62AUql2OzKZbFJsJy9d4PjDHNjTHNy5fPtmWjlFLKQ35ZR+CkCVgEdDbG7DPWWWyWSpfL/ZVSSvmHz8YIRKQ8kGiMiReRSGzKgFdEpJIxZp+TBKwbdim6UkplKzExkT179nDmzJlAVyWoREREUKVKFcLDXW2PkT1fzhqqBEwSuzF3IWCqMeY7EVnoBAnBpst92Id1UEoVIHv27KFkyZJER0fjfqO20GKM4fDhw+zZs4caNWp4dA5fzhpaR+bNSzDGtPfVNdObuSaO1+ZtYW98ApXLRDK4Ux26NYnyx6WVUj5y5swZDQIXEBHKlStHXibVFMgUEzPXxDFkxnoSEm0Cxbj4BIbMWA+gwUCpfE6DQGZ5vScFMunca/O2nA8CqRISk3lt3oUZd5VSShXIQLA3PiFX5UoplVMiwt13333+eVJSEuXLl6dr164BrFXeFMhAULlMZK7KlVIqp4oXL86GDRtISLBfLOfPn09UVP7uci6QgWBwpzpEhodlKIsMD2NwpzoBqpFSqiC58cYbmT17NgCTJ0/mjjvuOH/s1KlT9OvXjxYtWtCkSRNmzZoFQGxsLNdccw1NmzaladOmLF++HIBFixbRrl07evbsyeWXX07fvn3xd1boAjlYnDogrLOGlCq4XvjfRjbtPe7Vc9arXIrnb74i29f16dOHkSNH0rVrV9atW0e/fv1YsmQJAC+//DLt27dn4sSJxMfH07JlSzp06ECFChWYP38+ERER/PXXX9xxxx3nc6itWbOGjRs3UrlyZdq0acOyZcu4+uqrvfq7ZaVABgKwwUA/+JVSvtCwYUNiY2OZPHkyN910U4ZjP/zwA99++y2vv/46YKe87t69m8qVKzNgwADWrl1LWFgYW7duPf+eli1bUqVKFQAaN25MbGysBgKllMpOTr65+9Itt9zC008/zaJFizh8+PD5cmMM06dPp06djF3RI0aMoGLFivzxxx+kpKQQERFx/ljRomm5N8PCwkhKynb7b68qkGMESinla/369eO5556jQYMGGco7derEuHHjzvfzr1mzBoBjx45RqVIlChUqxGeffUZycnKmcwaKBgKllPJAlSpVePzxxzOVDx8+nMTERBo2bEj9+vUZPnw4AI8++iiTJk2idevWbN26leLFi/u7ym7liz2LmzdvbnRjGqXU5s2bqVu3bqCrEZRc3RsR+d0Y0zy794bcGIHmIFJKqYxCKhBoDiKllMospMYINAeRUkplFlKBQHMQKaVUZiEVCDQHkVJKZRZSgUBzECmlVGYhFQi6NYliVPcGRJWJRICoMpGM6t5AB4qVUjn21ltvUb9+fa644grefPPN8+UjRowgKiqKxo0b07hxY+bMmQPAsmXLaNiwIS1atGDbtm0AxMfH06lTJ7fJ5RITE4mJiaF27drUr1+fli1b8v333wMQHR3NoUOHvPo7hdSsIdAcREopz23YsIEJEyawcuVKihQpQufOnenSpQu1a9cG4Mknn+Tpp5/O8J433niD6dOnExsby7vvvssbb7zBiy++yNChQ93uLDZ8+HD27dvHhg0bKFq0KPv372fx4sU++71CqkWglFJ5sXnzZlq3bk2xYsUoXLgwbdu25ZtvvsnyPeHh4SQkJHD69GnCw8PZvn07cXFxtG3b1uXrT58+zYQJExg3btz5HEQVK1akV69eXv99UoVci0ApVYC0a5e5rFcvePRROH0aLsgMCsB999mfQ4egZ8+MxxYtyvJy9evXZ9iwYRw+fJjIyEjmzJlD8+ZpC3ffeecdPv30U5o3b84bb7zBRRddxJAhQ+jfvz+RkZF89tlnPP3007z44otur7Ft2zaqVatGqVKlsqyLN2mLQCmlcqhu3br8+9//pmPHjnTu3JlGjRpRuLD9Pv3II4+wfft21q5dS6VKlXjqqacAm1b6119/5aeffmLHjh1UrlwZYwy9e/fmrrvuYv/+/YH8lSxjTND/NGvWzCil1KZNmwJdhQyGDBlixo8fn6l8586d5oorrshQlpKSYjp27GiOHDli7rzzTrN582bz/fffm6FDh2Z43alTp0zZsmXN8ePHXV6zevXq5uDBg5nKXd0bYJXJwWestgiUUioXDhw4AMDu3buZMWPG+W0q9+3bd/4133zzDfXr18/wvkmTJtGlSxcuuugiTp8+TaFChShUqBCnT5/O8LpixYrxwAMPMHDgQM6dO3f+3J9//rnPficdI1BKqVzo0aMHhw8fJjw8nPHjx3PRRRcB8Mwzz7B27VpEhOjoaN5///3z7zl9+jSTJk3ihx9+AGDQoEH06NGDIkWKMHny5EzXeOmll3j22WepV68eERERFC9enJEjR/rsd9I01EqpfEPTULunaahzwNP005q2WilV0IVEIPA0/bSmrVZKhQKfDRaLSISIrBSRP0Rko4i84JTXEJEVIvKXiEwRkSK+qkMqT9NPa9pqpVQo8OWsobNAe2NMI6Ax0FlEWgOvAGONMbWBo8ADPqwD4Hn6aU1brZQKBT4LBM401pPO03DnxwDtgWlO+SSgm6/qkMrT9NOatlopFQp8uo5ARMJEZC1wAJgPbAfijTFJzkv2AD7vbPc0/bSmrVZKhQKfBgJjTLIxpjFQBWgJuJr35XL+qoj0F5FVIrLq4MGDeaqHp+mnNW21UupCmobaQ8aYeBFZBLQGyohIYadVUAXY6+Y9HwAfgF1HkNc6eJp+WtNWK6VSaRrqXBKR8iJSxnkcCXQANgM/Aakp/+4FZvmqDkop5U2ahjr3KgGTRCQMG3CmGmO+E5FNwFci8hKwBvjIh3VQShVkmobaK3w5a2idMaaJMaahMaa+MWakU77DGNPSGFPLGHO7Measr+qglFLepGmoNQ21UirANA21pqFWSqmA0zTUSikV4jQNdYBoGmqlFGga6qzkJQ11we8a+uor2Lo10LVQSqmgVbADwZkzMGAA1K0LffrAunWBrpFSSgWdgh0IIiJg40YYPBhmz4ZGjeDWW+HPPwNdM6WUh/JDd7a/5fWeFOxAAFCxIoweDbt2wYgRsGwZpKTYY6dPg/5RKZVvREREcPjwYQ0G6RhjOHz4MBERER6fI/QGi8+eBWfZNr17w99/w7BhdgWim7wfSqngkJiYyJ49ezhz5kygqxJUIiIiqFKlCuHh4RnKdc9id1KDAMB118GoUdC1KzRuDEOHQvfuEBbm/v1KqYAJDw+nRo0aga5GgVPwu4ay8vDDsG0bfPyx7Sbq1QtefTXQtVJKKb8K7UAAEB5uE1Bt2gRTp8L999vyRYtg/HhI0G0plVIFW8gFgplr4mgzeiE1YmbTZvRCZq6JswfCwuD22+GSS+zz6dPt1NMaNeC11+DEicBVWimlfCikAsHMNXEMmbGeuPgEDBAXn8CQGevTgkF6b78NP/0EDRrAM89A9eowbpzf66yUUr4WUoHgtXlbSEhMzlCWkJjMa/O2ZH6xiM11Pn8+/PorXHNN2lTTc+dgr8uN1ZRSKt8JqUCwN951f7+78vNatYJZs+Cxx+zzzz+3XUYPPQTbt3u5lkop5V8hFQgql4nMVXkmqesMrrsO+vWDTz6Byy6Dvn1h/XrvVFIppfwspALB4E51iAzPuEYgMjyMwZ3q5O5ENWrAu+/Czp0waJBtLdxzj65SVkrlSwU6ECQmp7DvWFq3T7cmUYzq3oCoMpEIEFUmklHdG9CtSZRnF6hc2c4o2r0bPvvMthji4+Hmm+3YggYGpVQ+UKBXFn/6yy5e/G4TAD2aVuHl2+rTrUmU5x/87pQta38AtmyB1avhhhugWTMYMgRuuw0KFeiYq5TKxwr0p1OPplGEFbL9+tNX7+Hy4XOJjpnN6t1HfXfRVq1gxw744AM4dgx69oR69XQdglIqaIVE0rmzSckMn7mBqav2ZDr254udiQj3UW6h5GS7MO2XX2DsWFs2d66dilq8uG+uqZRSjpwmnQuJQJDesm2H6Pvhikzl79zZhK4NK3vlGm7t3UtKtWocL1qciU1vZn67HjzUvaX3u6qUUgoNBNk6cOIMLV9ekKm8cCFhy0s3nu9S8qaZa+KY8tYUHlj6FR22/8ap8AimNelMhZef58YOjb1+PaVUaNNAkAuDpqxlhos0E1/+Xyuuqnmx167TZvRC4pzFa3UOxvLQiuncuGU5dz71Cd+M7mNXLBcp4rXrKaVCmwYCD+w8dIrrXl+UqfzS8sVZMKgtkseNa2rEzObCu13qzElORJRg5+gudqZRZCTExMCVV+bpWkopldNAUKBnDeVWjYuLEzu6C7Gju9Ai+qLz5TsOnqLGkDlEx8xmyV8HPT6/qxXMxyNK2PKUFLjqKli61P732mthzhxdi6CU8jltEWRj7d/xdBu/zOWx2NFdcnWu1Oyn6RPfRYaHZVzUdvIkfPQRvPGG3Ubz/fehf3+P66+UCl3aNeRlxhhqDJnj8ticgddQr3KpHJ1n5po4Xpu3hb3xCVQuE8ngTnVczxpKTITJk+HWW6F0afj2W7uCuV8/KFYsL7+KUipEBDwQiEhV4FPgEiAF+MAY85aIjAD+D0jtYxlqjHH9CesIhkCQ3sSlOxnprFhOr2rZSJY80943F33gAZg4ES6+GAYOhH/9K201s1JKuRAMgaASUMkYs1pESgK/A92AXsBJY8zrOT1XsAWCVOeSUrjs2e9dHlv4VFsuLV/CuxdcuhRGjbJjB8WLw8iRNumdUkq5kNNA4LNcQ8aYfcA+5/EJEdkMFKiVU0UKFzo/TjDi2418sjz2/LH2bywGoFREYdaN6OSdC159NcyebVNev/YaVKhgy48fh9hYaNjQO9dRSoUUv4wRiEg08DNQHxgE3AccB1YBTxljMiX/EZH+QH+AatWqNdu1a5fP6+kNh0+epdlLP7o8tmZ4Ry4q7oN1Am+8AU8/baefPvMMtG+ftneCUipkBbxrKF1FSgCLgZeNMTNEpCJwCDDAi9juo35ZnSNPXUPjx0NUFHTuDBERnp3DQ3WHz820NSZAm1rl+OLB1t670NGj8N578NZbsH8/NGkCgwdDnz4aEJQKYUERCEQkHPgOmGeMGePieDTwnTGmflbn8TgQpKTApZfCrl1QooTdJ+D2221QiMzhrmResO3ASTqMWezy2NaXbqRIYc+Xc6SfhRRdPIwxietpMvUju1fCwoX2RUlJULhAZxxXSrkQ8AVlYpfhfgRsTh8EnEHkVLcBG3xVBwoVgr/+gnnz7LfjH36A7t3hhRfs8eRkSMhmv2IvqFWhxPmFahe67NnviY6ZzdsL/sr1eVPXJcTFJ2CAnaeSudM0YOYX82HKFPuiuDioWhWefda2FpRS6gK+nDV0NbAEWI+dPgowFLgDaIztGooFHnIGlt3y2qyhxERYtMhuNVmrFvz4o9005pZb0loKfuo++n3XUXq8u9zlsZ2jbspROov0uYvSiyoTybIYZxrr9u22m2jmTJvH6J577Eyjyy/PU/2VUsEvKLqGvMVn00c3bIC334YZM+DwYShZ0gaFt9/26xz96JjZLsvf7N04yxTVrnIXAQjY3EXpbd0KY8bApEm2q2jvXihf3vNKK6WCngaC3EhMhJ9+gq+/huXLYd06CAuzK3tLlLCzcYoW9d31HXPW7+PRL1a7POaqWylHLYILHTgAixfbFhDY2UYtWtgus/Bwj+uulAo+Ggg8ZUzaTJvGjeGPP6BUKZvqoVcv6NjR50Ehq3QWU/q3ptWl5YAc5i7KysmTdl/lrVuhShW7Wvn//g/KlfPK76GUCiwNBN6QmAgLFtiWwowZEB8PDz4IEybYgJGU5PNv0e8v3s6o7/90eSx2dJec5y5yJyUFvvvOdoctWGDHSGbMgBtv9NJvoJQKFA0E3nbunB1crlTJztNfvx7atbNdKr16wXXX+XSKZmJyCrWHuU5nkb6VkCcbNth1Fy+9ZFsFCxbYVkPXrrarTCmVr2gg8LVNm+A//4FZs+yH5cUXQ48eMGIEXHKJTy/d493l/L4r02JsIPepsbPUrZv9/WrUgAEDbObTMmW8d36llE9pIPCXhASYO9fO21+wAHbutAPMqd0sV15p1zP4QPzpczQeOd/lsZ8HX0e1cnlMV52UZKedvv02LFliE909/7ydjqqUCnoaCAIhMTFtzKBNGzsDqUoV23XUpw80b+6zlA/upqCCl1oJq1fDuHHQti3cdx+cOAHLltkZVT4KdEqpvNFAEGgnTtjNZL76yq5sTkyEu++GTz/16WX//Oc4nd9c4vLY+hE3UDLCS4Pb770HjzwCderAY4/ZhWolS3rn3Eopr9BA4GdZzt45etR2sVSuDJ06wT//QIcOaS2Fyy7L+zVccNdKaF79IqY9clWuf8cMzp2DadNsoruVK+0U2wcegFdf1bxGSgUJDQR+lOv5/Bs22MHXn3+201CbNoU77rCDsW5WNOdlzcCCzft5YJLr+7f9PzcRViiP3VW//mrHEf75Jy3R3ebNNo2FZj9VKmA0EPiRRyt8wSaEmzLFrmD+/XebJbVqVbvA66KLMqSA8PgaF3DXSrjvqmhG3HJFjs/jUnKynWa6fz9Uq2ZbOgMHQt++us+yUgEQ8OyjoWSviw/orMrPi4qyCeB++81uTF+1qi1/8km7XqFzZ5sb6Ngxz69xgdQsqC/emvFD/5PlsUTHzM5y0DlbqWsNSpe2YwhhYdC/v/29YmI0+6lSQUoDgRdULuN6bwN35S5VqZL2ePRou9PYli12hk7Firy83PUgc66ukc7dV0a7TY2dGhC+XLHbo3MTEQH33w9r1ti8Ru3a2YR3p07Z4ydP2i4xpVRQ0K4hL8hzzh93jIEVK2DyZP4oVpE+hZuScvo0L85/lzl1rub32s148fYmebtGOs/OXM/nv7r+8M/zFNSDB9O6um65xWY/HTgQevf2S0I/pUKRjhH4WZ5z/uTwGt9O/B9jJzxN6bOnOFumLEXv7AN33glXXeW1gdmk5BRquUln8cWDrWhT6+K8XWDCBBg71g4oV6gADz9sfypVyv69Sqkc00BQkJ09a1czT55sU0CcOWMHm5s2tdM6ixTx2qVufWcpf+w55vJYnloJxtjcTW+/DbNn29Qczz2XMfurUipPNBCEihMnbFDo2dN+gD74oF0F3LevXaMQ5Z1WyfEziTQc8YPLYwueakvN8iU8P/m2bXaWVLlydm3CmDG226hHD90jQak80EAQhPzRfcRHH8H779uZSCI2K+pDD9nFa17i03QW33xjB8q3bbNB7NFH7R4JupuaUrnm1UAgIt1dFB8D1htjDnhQv1wpCIHA1YCyAH1bV+Olbg28f8GtW+HLL+GLL+w01HHj7N4D339vN9fxQvfR30dOc82rP7k8tva5jpQp5uE1Uuv59tvwww/QsKHdIMgP/BKslfITbweC2cCVQOr/9e2AX4HLgJHGmM88r2r2CkIgcLcgTICx2exNnCfG2AypxYrZDKLXXmtXL/fuDXfdZbOjeqFP3l0roWb54ix4qp3nJ960yW6v2a4dnD5tu7vuvdfOPPJyt5HPZn8pFSDeXlCWAtQ1xvQwxvQA6gFngVbAvz2vZuhwt/DLAK/N2+K7C4ukrept3doOzHbqBJ98YjOk1qplWw95lLom4euHr8xQvv3gqfPrEhKTU3J/4nr1bBAA2120bp0dD6laFYYOhR078lz3VK/N25IhCAAkJCb79t9HqSCQ00AQbYxJvyz0AHCZMeYIkOj9ahU8WS38yu3qYE88O3M9NZ+bT/TPhprV7+LFDxfYYNCoEURH2xd9/jl89pn95u2hFtFl3S5Uqz3se6JjZjNo6lrPTt6wIWzfbrfWbNUKXnkFatb0SiCDPKwQVyqfy2kgWCIi34nIvSJyL/At8LOIFAfifVe9gmNwpzq464DxdHVwTqUuFEt2ugGTjeGjdUd4tnRTuz9x6njBxx/bdNKXXGIHmH/9NU8rgFMDwphejTKUz1gdd76VkOvJCmFh0KWLnTa7ezf8979p2Vv//W/7s22bR/X1ygpxpfKhnAaCfwEfA42BJsAk4F/GmFPGmOt8VbmCpFuTKPq2rpYpGESGhzG4Ux2fXnvyir9zVj5/PixaZPdh/vxzO34wcGCer9+9aRW3rYQaQ+YQHTObCT970MUTFWX3RAAbsOLi4I03oHZtm+Z7yhS75iKHBneqQ2R4xr2Z/fHvo1Sg5Xj6qIhcgh0TSAF+M8b848uKpVcQBotTBWJWikfTPY8fh6lTbSrpq6+237Kfesqmyr7ppjwP1L4690/+u2h77uqUE3v32pbNhAk2m+szz9gupBzSWUOqIPH2rKEHgeeAhdiJLm2xs4Um5rWiOVGQAkEg1Bwy53y3UHphImwfdVPOTjJvnp2ts3+/TQtxzz02sVy9enmqW0qK4dKhc1we+/Ce5nQBzpWLAAAgAElEQVSoV9GzEycn25XLtWrZcYRFi2DkSJsN9bbbNL+RCgneDgRbgKuMMYed5+WA5cYYv7SZNRDkjbtkcnfldg1DYqJdxTxxoh2wLVTITu0sXdorqSHunbiSxVsPujyW54Vqs2bBE09AbKxdwXzffXahWh3t9lEFl7cDwQLgRmPMOed5EWCOMaZDnmuaAxoI8u7ZmeuZvOJvko0hTIQ7WlXN20K2AwdsZtSbb7bPO3a0g8z9+tkN7vOwoX3CuWTqPjfX5bE5A6+hXuVSnp04JcW2Ej74wAaGcuVgzx67tabmOFIFkLcDwadAA2CWU3QLsBLYCmCMGePiPVWBT4FLsOMKHxhj3hKRssAUIBqIBXoZY45mdX0NBEEuKcluYP/ll3ZsoUYN+437/vvTNtvxUMMR8zh+JsnlsTy1Ev75B/78065RSE6Gli3t4//7PzsuolQB4O1A8LzzMPXF4jwWAGPMCy7eUwmoZIxZLSIlgd+BbsB9wBFjzGgRiQEuMsZkuShNA0E+cfq0zRU0caLdu/i//7WzehIS7LftiAiPT73/+Bla/WeBy2O/DGlPpdJ5mOJ5+LCt5zff2KB2zTU2IPTooVtsqnzN24GgBTAU+y2+sFNsjDENc1GhWcA7zk87Y8w+J1gsym6sQQNBPrRzp+16KVXKJsGLibH7JvTrZ9Nl56EbxmdJ7/bvt1uDTphgZ0nNnm1nSJ05YweXtetI5TO+GCx+GtiA7eYBwBizK4eViQZ+BuoDu40xZdIdO2qMuSir92sgyCxfTXNcuRLeegumT7fz+hs2tAFh4MA8fbj+FnuE29/7xeWxTSM7UaxIYZfHspWSAkuX2hQcYWE2iM2aZbu67r5bN9BR+Ya3A8FSY8zVHlakBLAYeNkYM0NE4nMSCESkP9AfoFq1as127cpRzAkJ+TY52tGj8NVXdp5/4cKwfLktX7MGGjSwZR5y10qoXaEE8we19fi8AHz9tQ1ky5bZwHDjjXYaaupAuVJBytuB4HrgDmABNtkcAMaYGdm8Lxz4DpiXOqDstC60aygP3GUyjSoTybKY9gGokQdOnICSJeHIEfsNu1w5u07h/vvTUkZ4YOqqv3lm2jqXx3b85yYKFcpD986WLTY/06ef2iyukyfb8q1b81RnpXzF24Hgc+ByYCNpXUPGGNMvi/cINhXFEWPME+nKXwMOpxssLmuMeSar62sgyKhGzGxc/asJsDOv8+39LTHRrkmYOBHmzLHdMldfbfc0bp7t32+W3LUSejevyis9czy8lVlSEhw7ZoPXxo1Qv74d97j/frjjDluuVBDwdiBYb4zJ1aRzEbkaWAKsJy14DAVWAFOBasBu4HYni6lbGggy8laLIOjGGfbts9lPP/4Y/vc/uyp4zRo4dcr213s4nvDC/zby8bJYl8fyvFAtPt7WeeJEWLvWpt7o0gXefBOqV8/buVW2gu5vOMh4OxBMAMYaYzZ5o3K5pYEgI2+MEQT1OEP6xV133GHHFWrXtt+477nH432YjTHUGOI6ncXIW6/gniujPaywY+1aGxS++cY+LlXKpraIjLTrFHTWkVcF9d9wkPB2INgM1AR2YscIhFxOH80LDQSZ5fWbUL4ZZzh50s42mjgRfv7Zrlh+4AG7OjgPuo1fxtq/XWdQz3MrIX0gu/pqO8h82WU2iN11l7YUvCTf/A0HkLcDgcu/3JxOH80rDQTely/HGbZts91Gl1xiVzInJsK770Lfvh73y59JTOby4a7TWXzxYCva1Lo4LzW2K62nT7cDzIsW2bInn4QxmRbj51uB6p7Jl3/DfubVQBBoGgi8r0B8m1qwwO47ULSo3cv40UdtF4yHfLZQ7fxJYuGLL2zG1ttus/mannjCrk3o2DFP02cDJZDdMwXib9jHvL1nsSpgCsQmLNdfD+vX266i6dPt9pUtWtg8Qh5I3Txn5bDrMx1L3VFt56FTntc3OhqGDbNBAGDTJpvN9aaboEoVu9/DH394fv4ACOQ+zwXibzhIaIsghBWoGRfHj9td1ebNs4O1hQrBt99C3bp2oNlDPm8lnD1rp81++qlNaZGYCH//bQNDcrJdwBbEAt09U6D+hn1Au4ZUaEtKsrOLDhyATp1st1GXLh5/sG6IO0bXcUtdHvvj+RsoHZm3HdsAm/xu0SKb7A5sy+HkSTsG0r27nYUUZLR7Jrhp15AqcGauiaPN6IXUiJlNm9ELmbkmzv2LCxe2axBeeMF2H916K1x6qV285oH6UaXd7rvc6IUfiI6ZTdMX53t07vPKlUsLAgDNmsGOHXbabMWK0KsX/PRT3q7hZdo9UzBoIFD5QuqgZFx8AgaIi09gyIz1WQeDypXhuefsIO306XaBWvny9ti2bTbXkQct4tSA8N++TTOUHzl17vxYQlJyipt358Kzz9p6/vILPPigbS0sdVolZ87A4sV2JXYAdWsSxajuDYgqE4lgWwI6jz//0a6hEJaf+le93gXxr3/Z/RIaN7bdRnfeCcWLe1w/d2MJna6oyPt35y1VxnmJiXDunK3n9OnQs6fd+OeOO2z3UUO/LOtR+Yh2DaksefQNO4D2uggCWZVn65VX7D4JKSk2k2jlyvYbuIdSWwlPdMg4MD1v4/7zrYQ8Cw9PC1adO9upqA0awBtvQKNG9vGBA3m/jgo5GghCVCCn/XmichnXO5C5K89WiRI2AKxda1f+3nyz3UkNbHfR3Ll21k4uPdHhMrdjCakBYfxP2zyrc3rFi9tWzOzZNkfT+PFwxRVpXV+vvWbzHe3dm/drqQJPu4ZCVKCn/eWWXxYupaaGWLrUbldZvToMGGDXKVyU5d5JWbr/45X8tOWgy2NemYLqSseO8OOP9vdp29Z2H/XooZlRQ4x2Daksef0bto/5ZVAyNT9Q69a2D756dRg82M7pf/RRu3eCG1nNaPr4/pbEju7CtpdvzPS+1FbCvI2eLYJza/58+PNPeP5522J46CH7GGx32IkT3r2eyte0RRCiNHNjDq1ZY3cnW7jQbkATEQG7d9vgUMh+j/LkXl7x3FxOnXPd9eT1VoIxdsVyiRJ25tTy5XZVdpcuNjVHly42Q6oqcHRBmcpWfpo1FHDnzkGRInbcoFYtGxAeewzuuYc276z0eEZT/OlzNB7pev3Bj4PaUqtCCa9UP4O//oJx42DqVNi/3waIbt3soHOFCt6/ngoYDQRK+UJSEkyZYgdiV62CMmX44LL2fNzsZvaVKp/hpbkdb/F5OosLJSXZtQiTJ9uFaps22QR+//ufDQ7XXhv0KS5U1jQQKOVLxtiFXm+9RdK0aTzcbRg/1m5F4eQkkgqFgYjHaxy2HThJhzGLXR5b9WwHLi5RNK+1zyz9HgpNmtjZVJUqQe/etvtIN9bJlzQQKOUnc+f+xlNLDnAqGZ76+TOuiV3DpCt70C7mIW5tkbdNaPzeSgC7Nejs2balMGeO7RZ76CF47z3fXE/5jAYCpfwodbyl1dLZPPHrFKodjoNq1eDxx216iDwmjFu05QD3ffyby2NbXupM0cI+6sI5dsxmc61Z006p3b4duna1eY9697Z7K6igpYFAKT9KP/AeVaoorxf7m9bffGK31+zb16bI9hJ3rYSW0WWZ+vCVXruOS6tX230TFi+23Un169ug8K9/Qdmyvr22yjUNBEr5SZbTR5P3QbFi9pvzn3/abKiDBtkNdPLoo6U7efG7TS6P7Rx1E+LLPv19+2DaNDvzaOVK+7xsWfj9dyhd2s6sUgGngUApP8lxQrwZM2xK6ePH7ab2Tz1lU1t4YWaOu1bC0Jsup/+1NfN8/iwdPpy2YrltW9sKatIEbr/d/mhQCBgNBEr5Sa7SdRw/DhMn2umnu3bZRHFr1nhtmuYrc//k3UXbXR7z2eByert3p7UUVqywZQ88AB9+6Ptrq0w0ECjlJx6lyE5KsoOwf/9tu4qMsYnjune3mVDzKCXFcOnQOS6PTbinOR3rVcz1OXO9ADE1KFSrZlNmHz1qs6bedpttKdT0cUtFaSBQyl+8kq7jzz/tOELhwjZB3KBBNrW0F9z90QqW/HXI5bGcthK88jtu3GhbB6kthaZNbUDo109XNPuIBgKl/Mgr6Tq2b7d5jSZOtHP5O3SwXSrVs1+LkJPrJ5xLpu5zc12+f/bAq7micmm35/fqxkC7dtmWwtdf26CwdSvUrg2bN9s0HtpS8BoNBErlV0ePwgcf2I1nfv3Vzjrats0GhPDwTC/35Nt6g+fnceJskstjrloJPktbvndvWldYr142OKS2FLT7KM80ECiV36WmfUhOhssvh7NnbZfRgw/aXECOvHxb/+fYGVqPWuDy2Mqh11OhVESer5FjqS2F1CmpYMcWvv7aO+cPQRoIlPIjX2RyTT3nvqOn6L5/PTHrv+Xi1SugTBm7P8Jjj8Ell3jt27q7KahlioUz4uYr/Ju2PDUolCxpd5JLTIROnezP7bfDpZd6/5oFUMADgYhMBLoCB4wx9Z2yEcD/AanbNQ01xrie2pCOBgIVzLy9t8PMNXG88L+NHD2dmKE8MjyM92on0vbbSXZNwtSp0LMnbUYtIO7YmUzn8fTb+oa4Y3Qdt9TlscqlI9h37Iz/05bv2mW7jlJbCs2a2YBwzz02OZ5yKRh2KPsE6OyifKwxprHzk20QUCrYeXP/59SgcmEQSD3n0L3F7TflrVvtNEzgw7/n8uE3L9N0z+bzr40MD2Nwpzq5vj5A/ajSbvdd3nvsDAboWK+if/euqF7dDizv3Gn3Yw4Lg5gYO8AONlBs88Je0CGqsK9ObIz5WUSifXV+pYLFXhd951mVZ8VVUHF5znSrdevWqkTNLzfT4YvB/FalHlOu78vVA+/xygd1ajCYu2EfD3+++nz5J8tj+WR5LOCHdBbpRUfD00/bn127oGpVWz5mDLz9tp1y27On/bn8cp9Vo6Bt6hSIPYsHiMg6EZkoIm53BBeR/iKySkRWHTzoeuNvpYKBN/d/zi54uDznoEEUidsDb71Fi0IneX3SMLpNHJ3ra2elc/1KblsJNYbMITpmNp/9EuvVa2arevXz24Xy1FMwdqwdRB8+HOrWtRvr+EBqqy0uPgEDxMUnMGTG+gz7VOc3Ph0sdloE36UbI6gIHAIM8CJQyRjTL7vz6BiBCmbeHCNwNzsnx+dMTISvvrLfhlu0sF0pc+bYHEfFiuWqLtmZuupvnpm2LlN5qxplmfKQj7OgZiUuzq7aTkiAwYPt7KubbrLTUnv0sHmQ8tCC8csMKi8JhjGCTIwx+40xycaYFGAC0NKf11fKF7o1iWJU9wZElYlEsB8Ing4UD+5Uh8jwzHmHykSG5+yc4eFw991p2U2//hoGDLBdKi+9ZNcoeEmv5lWJHd2Fsb0yroBesfMI0TGziY6ZTeyhU167Xo5FRdnfefBg+/z4cZvS45VX7CBzzZrwzDOwJfdjOODdrsBg4e8WQSVjzD7n8ZNAK2NMn+zOoy0CFUq83v+8dCmMHm13HStRwk47/c9/vFbXC1tDrvRsVoXXb/dOygyPHToEs2bZwfYff7Q7sPXsaRe17dwJV16Z1tWUhYLYIvDl9NHJQDvgYmA/8LzzvDG2aygWeCg1MGRFA4FSXrBuHbz6qg0GqdtO7t5tk8J5yN2HYuXSEew/cZbklMyfL78N60D5kj7Ydzk3jh6FyEiIiIBRo2DoUDsNtXt3GxyuucZtRlhvTxf2pYAHAm/SQKCUF6WuWF6xwn4L7t4d/v1vjzbLyclitllr43j8q7WZXjPw+toM6nhZrq/pdceP29bStGl2POXMGdu9tGOHzX3kQn6ZNaSBQCmVtYMH7ZTLd96B+Hho397Oze/QIceDqbnpJjmTmMzlw10nvdvwQidKFPXZbPacO3kSvv/erkkYMsSWdetmN97p2ROuv95tcAhGGgiUUjlz4oRNcjdmDJw+bfdISJfLKCuedpN8uGQHL83enKn8P7c14M5WnndVeV1ysp1xNWuWbTmULg233mrTXrRpE+jaZUsDgVIqd86ehQ0b7MyalBT7gXfzzTaNQ0SE27flpZvk2OlEGo38weWxrS/dSJHCgVjq5MLZs3aAedo0GxRGjrQzk44cgYUL4cYboXjxQNcyEw0ESinP/fOPDQKrVsEll8CTT8LDD0OpUj675IvfbeKjpTszlX9wdzNuuOISn1031xIT7XTUyEiYNAnuu88+7tzZrlPo2tW2HIKABgKlVN4YY7/tjh4NP/7IyaLF6XXHKI7VucKng6N74xO4avTCTOUlIwrzx3M3UKiQn9JZ5ERSkp2eO326TQS4d68dQ9i9GypWtC2rHExJ9RUNBEopr5i5Jo7Pxs+g2+q5jOjwEMmFwmj/9zp639meTl1a+fTaD3/2O3M3/pOpfPojV9KselmfXjvXUlLsTKxly2wuJIA+feygfI8eNkmgnzOlaiBQSnnFhTODCqUks+S9B6l46giF777LTj2tW9enddi6/wQ3jP05U3nDKqX5dsDVPr12nrz8Mnz2mV3FLAJXXQWPPAJ9+/rl8kGZYkIplf9cmDohpVAYPe96lU+bdLF7Ilxxhf3Gu3Gjz+pwWcWS55Pe1auUNk6xbs8xomNmU2PIbA6fPOuz63ts2DC7F/OGDTBihJ2eutmZLXXunF3gt3VrQKsI2iJQSmUjy7UCDzSwaxHGjbP95NdfbwdTXeyt7G0rdx6h1/u/ZCoff2dTujQM4s1qkpPtquWlS+0KZoD69W0w7dHDPvZSWm/tGlJKeUWO1gqcPGmnT4rYGUarVtlvw506ee1DzR1jDP9dtD3TRkDXX16BN/s0pmSE74OSx3bvtplSZ8yAJUvsAP2KFdCyZcZ76iENBEopr8nVWoEJE+w8+z177JqEoUPt6lw/zJ7ZduAEvd//lcOnzmUo/7RfS669rLzPr58n+/fbVBf33Wfv1YABtvXw7rsen1IDgVIqcM6ds4Oko0fbdA2DB9v+cD9JTjG8MvdPPvh5R4by7k2i+E/3BkS4SPUddL75BsqXh6s9HwzXQKCUCrykJLsnQpMmdrOcDRtg+XK4914o6p8MpH/8HU/3d5dnyoQ649GraFrN7SaJBYIGAqVU8Bk61KZ9joqyc+3/7//8lprhbFIyw2duYOqqPRnK728TzbCb6lI4rOBNotRAoJQKPsbYnD0vvwyLF8PFF8Ozz8Ljj/u1Gsu2HaLvhysylJWODOfrh6/ksool/VoXX9J1BEqp4CMCHTvCokV2+mSLFjYtA9ggcfiwX6rRptbFxI7uwsYXOnFDvYoAHEtI5IaxPxMdM5u3fvyLFBeb6hRU2iJQSgVWaj6e77+3Of/797fdRlH+3ehl7oZ/ePjz3zOUVS9XjM8faEXVssX8Whdv0RaBUip/SJ1WWquWDQTjxsGll8JDD9ldwvykc/1LiB3dhTXDO9Kqhs1jtOvwaa559SeiY2YzaXks+eGLsye0RaCUCi47dtipph9/bJO07dgRsAyeU3/7m2emr8tQ1rBKaT66t0Xg913OAR0sVkrlb3FxsH07XHutXZcwYIDdE6FpU79XZd+xBO7/+Df+/OdEhvK3+jTm1sbBt1dxKg0ESqmCY/VquO46u13kjTfa9BUB2CrSGMOHS3by8pyM22xeU/ti3rmzKaUjgyudhQYCpVTBcuwYjB8PY8fCoUPQtq1NdFeuXECqs+PgSe6csIJ/jp/JUP7xfS247vIKAanThTQQKKUKplOnbD6j+fPhu+/slNQ//4TLLgvIWEJKimHM/K2889O2DOU3N6rMqz0aElkkcOksNBAopULD0aNQvTrUqGG7jHr0sGmeA2BD3DF6vrecM4kpGcq/fvhKWkT7f0c1nT6qlAoNJUvaLqOzZ6F3b5vP/7PPbJ4jP6sfVZo/X7yRrS/dyF2tq50vv/29X4iOmc3wmRtITE7J4gyBoS0CpVTBkJxsxwxeegnWr4c1a6Bx40DXihU7DtP7g18zlBUrEsa0h6+iXuVSbt7lHdo1pJQKTSkp8MsvabOKhg6FKlWgXz+IiAhYtRLOJTN42h98t25fhvIb6lXkvbuaUahQxg1ocrUHhBvaNaSUCk2FCqUFgaQkm/b6X/+yq5XHjoXTpwNSrcgiYXSoW5HIC/ZC+GHTfi4dOoerRi0g9tApIG1XuLj4BAwQF5/AkBnrmbkmzid181kgEJGJInJARDakKysrIvNF5C/nvwU7GbhSKrAKF4affoKFC+1+CIMGQXS0nXEUAK/N25Jhy8/09h47Q7vXFxEdM5vnZm3I9LqExORM23F6iy9bBJ8AnS8oiwEWGGNqAwuc50op5TsidjHawoU242nLljYogE1fcfSo36qyNz7BdRWBMb0anX9+/IzrgW53788rnwUCY8zPwJELim8FJjmPJwHdfHV9pZTKpE0bu/agalX7/OGHbQth2DC7SM3HKpeJdFvevWkVYkd3YeXQ6wkPc71hvbv355W/xwgqGmP2ATj/DY7ld0qp0PTaa9Cpk901rXp1m/76n398drnBnepkGiOIDA9jcKc6559XKBXBaz0bEVG4UJav86agHSwWkf4iskpEVh08eDDQ1VFKFUSNGsHUqbBxI3TvbgeTP/nEZ5fr1iSKUd0bEFUmEgGiykQyqnuDTLOBujWJYnSPhtm+zlt8On1URKKB74wx9Z3nW4B2xph9IlIJWGSMyTbE6fRRpZRfbNsGFSpAqVLw9dd2UDkmxs44yoeCdfrot8C9zuN7gVl+vr5SSrlXq5YNAgA7d8KkSTaH0X33wRbfzNgJBr6cPjoZ+AWoIyJ7ROQBYDTQUUT+Ajo6z5VSKvg884wNBo89ZruP6taFIUMCXSuf0JXFSimVnQMHYMwYuylOr15w8iRs3RqQTXJyI1i7hpRSKv+pUAFGj7ZBAOCDD6BZM+jaFVasCGzdvEADgVJK5dYDD9jkdr/8Aq1b2ymoS5cGulYe00CglFK5Vbq0XYS2axe8+qrNdDp8eKBr5TENBEop5akSJWDwYIiNTVt/EBcH118PP/wA+WAMFjQQKKVU3hUrZlcmg81ftHWr7S5q3dqmtAjygKCBQCmlvOmaa+zCtPfft7ONbr4ZWrWCc+cCXTO3NBAopZS3FS0K/fvblsHEidChAxQpYo8tWWJ3UwsihQNdAaWUKrDCw+H++9Oeb9gA115r02APGwZ9+tg9EwJMWwRKKeUvdevClCn2w//uu6FePZvGIsn1/gP+ooFAKaX8JSzMLkr74w+YPh2KF7fbaB47FtBqaSBQSil/K1TIpr1evRpWrYJy5ezMou7d4d134exZ/1bHr1dTSimVRiRt28wjR2DfPnj0UahZE8aNgwTfbE15IQ0ESikVDMqVg+XL7R4Il14KAwdmHGj2ocAPVyullLJE7FTTDh1g8eK0vRF8TAOBUkoFo7Zt/XYp7RpSSqkQp4FAKaVCnAYCpZQKcRoIlFIqxGkgUEqpEKeBQCmlQpwGAqWUCnEaCJRSKsSJCfIt1ABE5CCwK9D1uMDFwKFAV8IFrVfuaL1yR+uVO4GuV3VjTPnsXpQvAkEwEpFVxpjmga7HhbReuaP1yh2tV+4Ea70upF1DSikV4jQQKKVUiNNA4LkPAl0BN7ReuaP1yh2tV+4Ea70y0DECpZQKcdoiUEqpEKeBQCmlQpwGAjdEZKKIHBCRDenKyorIfBH5y/nvRU65iMjbIrJNRNaJSFM/12uEiMSJyFrn56Z0x4Y49doiIp18VKeqIvKTiGwWkY0i8rhTHtD7lUW9An2/IkRkpYj84dTrBae8hoiscO7XFBEp4pQXdZ5vc45H+7len4jIznT3q7FT7re/e+d6YSKyRkS+c54H9H5lUa+guF+5YozRHxc/wLVAU2BDurJXgRjncQzwivP4JuB7QIDWwAo/12sE8LSL19YD/gCKAjWA7UCYD+pUCWjqPC4JbHWuHdD7lUW9An2/BCjhPA4HVjj3YSrQxyl/D3jEefwo8J7zuA8wxUf3y129PgF6uni93/7unesNAr4EvnOeB/R+ZVGvoLhfufnRFoEbxpifgSMXFN8KTHIeTwK6pSv/1Fi/AmVEpJIf6+XOrcBXxpizxpidwDagpQ/qtM8Ys9p5fALYDEQR4PuVRb3c8df9MsaYk87TcOfHAO2BaU75hfcr9T5OA64XEfFjvdzx29+9iFQBugAfOs+FAN8vV/XKht/uV25pIMidisaYfWA/ZIAKTnkU8He61+0h6w8cXxjgNDcnpnbBBKJeTjO8CfbbZNDcrwvqBQG+X053wlrgADAf2/qIN8Ykubj2+Xo5x48B5fxRL2NM6v162blfY0Wk6IX1clFnb3sTeAZIcZ6XIwjul4t6pQr0/coVDQTe4erbhj/n5b4L1AQaA/uAN5xyv9ZLREoA04EnjDHHs3qpizJ/1ivg98sYk2yMaQxUwbY66mZx7YDVS0TqA0OAy4EWQFng3/6sl4h0BQ4YY35PX5zFtQNZLwjw/fKEBoLc2Z/alHP+e8Ap3wNUTfe6KsBef1XKGLPf+R84BZhAWneG3+olIuHYD9svjDEznOKA3y9X9QqG+5XKGBMPLML2GZcRkcIurn2+Xs7x0uS8ezCv9ersdLEZY8xZ4GP8f7/aALeISCzwFbZL6E0Cf78y1UtEPg+C+5VrGghy51vgXufxvcCsdOX3OLMCWgPHUrtE/OGCfsbbgNQZRd8CfZxZFDWA2sBKH1xfgI+AzcaYMekOBfR+uatXENyv8iJSxnkcCXTAjl/8BPR0Xnbh/Uq9jz2BhcYZffRDvf5MF8wF2w+f/n75/N/RGDPEGFPFGBONHfxdaIzpS4Dvl5t63RXo++WRQIxQ54cfYDK22yARG8kfwPYzLgD+cv5b1nmtAOOx/bzrgeZ+rtdnznXXYf/YKqV7/TCnXluAG31Up6uxTdx1wFrn56ZA368s6hXo+9UQWONcfwPwnFN+KTbwbAO+Boo65RHO806JMN8AAAG0SURBVG3O8Uv9XK+Fzv3aAHxO2swiv/3dp6tjO9Jm5wT0fmVRr6C5Xzn90RQTSikV4rRrSCmlQpwGAqWUCnEaCJRSKsRpIFBKqRCngUAppUJc4exfopQSkRHASaAU8LMx5sfA1kgp79FAoFQuGGOeC3QdlPI27RpSyg0RGSZ2X4IfgTpO2Sci0tN5PFpENjnJxV5Pd/w9EVkiIludfDRKBTVtESjlgog0w6YNaIL9/2Q18Hu642Wx6SkuN8aY1NQMjmigLTax3U8iUssYc8ZfdVcqt7RFoJRr1wDfGGNOG5ux9NsLjh8HzgAfikh34HS6Y1ONMSnGmL+AHdhMlEoFLQ0ESrnnNv+KsXnuW2Izm3YD5mbxPs3jooKaBgKlXPsZuE1EIkWkJHBz+oPOHgeljTFzgCewexukul1EColITWxitC3+qrRSntAxAqVcMMasFpEp2Iylu4AlF7ykJDBLRCKwWSWfTHdsC7AYqAg8rOMDKthp9lGlvEhEPsGmI56W3WuVChbaNaSUUiFOWwRKKRXitEWglFIhTgOBUkqFOA0ESikV4jQQKKVUiNNAoJRSIe7/Ae8Lwys2DfWeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ovbserved CI\n",
    "plt.scatter(X.disp, y)\n",
    "plt.plot(X.disp, summary['mean'], label = 'Mean')\n",
    "x, lower = zip(*sorted(zip(X.disp, summary['mean_ci_lower'])))\n",
    "plt.plot(x, lower, 'r--', label = '95% CI')\n",
    "x, upper = zip(*sorted(zip(X.disp, summary['mean_ci_upper'])))\n",
    "plt.plot(x, upper, 'r--', label = '95% CI')\n",
    "plt.xlabel('disp')\n",
    "plt.ylabel('mpg')\n",
    "plt.title('mpg vs. disp with 95% CI')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Why do we have a confidience interval for our predicted value? Why isn't the prediction just a single number?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "Our data is only a sample from the entire population. The single mean value predicted by our regression represents our prediction given that our sample were the entire population. However, we know that if we had taken a different sample, our regression would have different coefficients and our prediction would have been different. We include a confidence interval to quantify this uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3 Someone asks what `mpg` you would predict for a `disp` value of 400. What do you tell them, paying attention to the confidence interval (5.2.3) above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.113807</td>\n",
       "      <td>0.983136</td>\n",
       "      <td>11.105976</td>\n",
       "      <td>15.121638</td>\n",
       "      <td>6.176537</td>\n",
       "      <td>20.051077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  13.113807  0.983136      11.105976      15.121638      6.176537   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0     20.051077  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = model.get_prediction([400,1]).summary_frame()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  13.113806771049497\n",
      "95% CI Lower (observed):  6.1765369580687866\n",
      "95% CI Upper (observed):  20.051076584030206\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print('prediction: ', summary['mean'].values[0])\n",
    "print('95% CI Lower (observed): ', summary['obs_ci_lower'].values[0])\n",
    "print('95% CI Upper (observed): ', summary['obs_ci_upper'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "If I had to predict a single value, I would predict that the value is 13.11. I would also say that I am \"reasonably confident\" that the value is between 6.17 and 20.05. We use the prediction confidence interval because this takes into account both the sampling error and the irreducible noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4 Why does the 95% confidence interval for the predicted `mpg` appear to curve as we move away from the data's center?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *your answer here*\n",
    "\n",
    "Intuitively, the data curves because, due to our \"samples\" coming from the same population, the variation in the regression coefficients are correlated. If the sample from our population leads to a higher intercept term, the slope will be more negative. Likewise, if the the intercept term is lower, the slope will be less negative. This results in the confidence interval widening as we move away from the center of the data.\n",
    "\n",
    "Mathetmatically, we see this from the formula for the confidence interval:\n",
    "\n",
    "$$\n",
    "\\text{CI} = y \\hat \\pm t_{n-2}s\\sqrt{\\frac{1}{n}+\\frac{(x-\\overline x)^2}{(n-1)\\sigma}}\n",
    "$$\n",
    "\n",
    "As we get further away from the center of the data, $(x-\\overline x)^2$ grows where $x$ is the $x$-value for which we are calculating the confidence interval and $\\overline x$ is the mean of the x values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 6 [8 pts] </b></div>\n",
    "Hopefully, in the question above you recognized that uncertainty in the beta coefficients could impact the certainty of our predictions. In this question and the next, we're going to explore properties of the data that can make us more or less certain of the values of the betas.\n",
    "\n",
    "**6.1** Fit a multiple linear regression to the full X matrix (on the car data). That is, predict `mpg` using `cyl`,`disp`,`hp`,`wt`, and `qsec`.\n",
    "\n",
    "**6.2** The formula for the covariance of the vector of betas, assuming the linear regression model holds, is:\n",
    "$${\\rm Cov}(\\beta) = \\sigma^2\\left(X^TX\\right)^{-1}.$$\n",
    "Compute and display this matrix for the car data. \n",
    "\n",
    "**6.3** Verify that the SE reported by statsmodels matches the square root of the variance listed for that variable in your calculated covariance matrix.\n",
    "\n",
    "**6.4** Interpret the matrix formula above. At a minimum, discuss what affects our ability to estimate the betas accurately. When would you expect two betas to have large/small covariances? [This is intended as an open-ended question. You will be graded only on the specified minimum].\n",
    "\n",
    "**Hint**: we don't know $\\sigma^2$, but we can estimate them.<BR>\n",
    "**Hint**: remember that numpy's normal distribution expects a standard deviation and not a variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1 Fit a multiple linear regression to the full X matrix (on the car data). That is, predict `mpg` using `cyl`,`disp`,`hp`,`wt`, and `qsec`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "full_model = OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2 The formula for the covariance of the vector of betas, assuming the linear regression model holds, is:\n",
    "$${\\rm Cov}(\\beta) = \\sigma^2\\left(X^TX\\right)^{-1}.$$\n",
    "Compute and display this matrix for the car data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.487897883027459"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute variance\n",
    "y_hat = full_model.predict(X)\n",
    "var = np.sum((y.reshape(32,)-y_hat)**2)/(len(y)-X.shape[1])\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4878978830274585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98.368517</td>\n",
       "      <td>-3.780794</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>-0.083821</td>\n",
       "      <td>4.959981</td>\n",
       "      <td>-4.638669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.780794</td>\n",
       "      <td>0.511577</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.169858</td>\n",
       "      <td>0.128479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018899</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.083821</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.004399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.959981</td>\n",
       "      <td>-0.169858</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>1.568470</td>\n",
       "      <td>-0.347664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.638669</td>\n",
       "      <td>0.128479</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>-0.347664</td>\n",
       "      <td>0.237618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "0  98.368517 -3.780794  0.018899 -0.083821  4.959981 -4.638669\n",
       "1  -3.780794  0.511577 -0.004108 -0.001251 -0.169858  0.128479\n",
       "2   0.018899 -0.004108  0.000142 -0.000024 -0.008850  0.000328\n",
       "3  -0.083821 -0.001251 -0.000024  0.000233 -0.004826  0.004399\n",
       "4   4.959981 -0.169858 -0.008850 -0.004826  1.568470 -0.347664\n",
       "5  -4.638669  0.128479  0.000328  0.004399 -0.347664  0.237618"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "cov = var*np.linalg.inv(np.dot(X.T, X))\n",
    "pd.DataFrame(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3 Verify that the SE reported by statsmodels matches the square root of the variance listed for that variable in your calculated covariance matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshfeldman/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.91809038, 0.71524643, 0.01190742, 0.01526723, 1.25238578,\n",
       "       0.48746086])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(np.sqrt(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 26 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>6.18e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:49:09</td>     <th>  Log-Likelihood:    </th> <td> -72.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   156.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   164.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   35.8736</td> <td>    9.918</td> <td>    3.617</td> <td> 0.001</td> <td>   15.487</td> <td>   56.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>   <td>   -1.1561</td> <td>    0.715</td> <td>   -1.616</td> <td> 0.118</td> <td>   -2.626</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>  <td>    0.0119</td> <td>    0.012</td> <td>    1.004</td> <td> 0.325</td> <td>   -0.013</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>    <td>   -0.0158</td> <td>    0.015</td> <td>   -1.037</td> <td> 0.309</td> <td>   -0.047</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>    <td>   -4.2253</td> <td>    1.252</td> <td>   -3.374</td> <td> 0.002</td> <td>   -6.800</td> <td>   -1.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>  <td>    0.2538</td> <td>    0.487</td> <td>    0.521</td> <td> 0.607</td> <td>   -0.748</td> <td>    1.256</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.925</td> <th>  Durbin-Watson:     </th> <td>   1.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.085</td> <th>  Jarque-Bera (JB):  </th> <td>   3.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.782</td> <th>  Prob(JB):          </th> <td>   0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.453</td> <th>  Cond. No.          </th> <td>6.73e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.73e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.850\n",
       "Model:                            OLS   Adj. R-squared:                  0.821\n",
       "Method:                 Least Squares   F-statistic:                     29.51\n",
       "Date:                Wed, 26 Sep 2018   Prob (F-statistic):           6.18e-10\n",
       "Time:                        20:49:09   Log-Likelihood:                -72.003\n",
       "No. Observations:                  32   AIC:                             156.0\n",
       "Df Residuals:                      26   BIC:                             164.8\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         35.8736      9.918      3.617      0.001      15.487      56.261\n",
       "cyl           -1.1561      0.715     -1.616      0.118      -2.626       0.314\n",
       "disp           0.0119      0.012      1.004      0.325      -0.013       0.036\n",
       "hp            -0.0158      0.015     -1.037      0.309      -0.047       0.016\n",
       "wt            -4.2253      1.252     -3.374      0.002      -6.800      -1.651\n",
       "qsec           0.2538      0.487      0.521      0.607      -0.748       1.256\n",
       "==============================================================================\n",
       "Omnibus:                        4.925   Durbin-Watson:                   1.682\n",
       "Prob(Omnibus):                  0.085   Jarque-Bera (JB):                3.534\n",
       "Skew:                           0.782   Prob(JB):                        0.171\n",
       "Kurtosis:                       3.453   Cond. No.                     6.73e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.73e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "They are equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.4 Interpret the matrix formula above. At a minimum, discuss what affects our ability to accurately estimate the betas. When would you expect two betas to have large/small covariances? [This is intended as an open-ended question. You will only be graded on the specified minimum].**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "Generally speaking, there are two forces that affect our ability to accurately estimate betas. The first is the degree to which a linear combination of the covariates can predict the dependent variable. This is represented by the $\\sigma^2$ term, which decreases as our linear model becomes more predictive. \n",
    "\n",
    "The other force that affects our ability to estimate the coefficients is the degree to which our covariates are orthogonal. When they are close to orthogonal, $(X^TX)^{-1}$ becomes closer to being a diagonal matrix, which means that variation in one parameter has little impact on other parameters. If the covariates are collinear, even if our model can predict the dependent variable well, there will still be variation in the coefficients because one can reach the same y vector with different linear combinations of the covariates. This, in turn, increases our uncertainty in the estimates of our beta values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 7 [12 pts]: What affects our knowledge of the betas? </b></div> \n",
    "\n",
    "\n",
    "**7.1** Create a separate dataset `edit1` with a new column `noise` that is totally independent of the other columns (random values from an exponential distribution). What effects do you see on our ability to estimate the betas?\n",
    "\n",
    "**7.2** Create a separate dataset `edit2` with a new column `ratio` that is the ratio of a car's horsepower to its weight. What change do you see in our certainty about weight's effect on mpg?\n",
    "\n",
    "**7.3** Create a separate dataset `edit3` with a new column `combo` that is horsepower+displacement+weight+ Normal(0,.01) noise. How well can we estimate the betas for this dataset, and which ones are correlated?\n",
    "\n",
    "**7.4** If you could choose the different features in your data (either because you're running a lab experiment manipulating the X values, or by deciding which columns to measure/keep), how would you like your features to relate? Specifically, how can you get as good an estimate of the betas as possible?\n",
    "\n",
    "**Hint**: Should introducing pure noise give us meaningfully more accurate beta values? <br>\n",
    "**Hint**: What happens if $X^TX$ is diagonal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answers\n",
    "\n",
    "**7.1  Create a separate dataset `edit1` with a new column `noise` that is totally independent of the other columns (random values from an exponential distribution) ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_covariance(model, y, X):\n",
    "    y_hat = model.predict(X)\n",
    "    var = np.sum((y.reshape(X.shape[0],)-y_hat)**2)/(len(y)-2)\n",
    "    cov = var*np.linalg.pinv(np.dot(X.T, X))\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.648700</td>\n",
       "      <td>-2.944955</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>-0.068860</td>\n",
       "      <td>4.156655</td>\n",
       "      <td>-3.709904</td>\n",
       "      <td>-0.312178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.944955</td>\n",
       "      <td>0.404197</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.126290</td>\n",
       "      <td>0.099587</td>\n",
       "      <td>-0.009525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013115</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.007364</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.068860</td>\n",
       "      <td>-0.001071</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.004418</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.156655</td>\n",
       "      <td>-0.126290</td>\n",
       "      <td>-0.007364</td>\n",
       "      <td>-0.004418</td>\n",
       "      <td>1.290439</td>\n",
       "      <td>-0.285919</td>\n",
       "      <td>-0.068506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.709904</td>\n",
       "      <td>0.099587</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>-0.285919</td>\n",
       "      <td>0.189875</td>\n",
       "      <td>0.015037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.312178</td>\n",
       "      <td>-0.009525</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>-0.068506</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.086243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6\n",
       "0  78.648700 -2.944955  0.013115 -0.068860  4.156655 -3.709904 -0.312178\n",
       "1  -2.944955  0.404197 -0.003291 -0.001071 -0.126290  0.099587 -0.009525\n",
       "2   0.013115 -0.003291  0.000115 -0.000015 -0.007364  0.000344  0.000491\n",
       "3  -0.068860 -0.001071 -0.000015  0.000191 -0.004418  0.003602  0.000775\n",
       "4   4.156655 -0.126290 -0.007364 -0.004418  1.290439 -0.285919 -0.068506\n",
       "5  -3.709904  0.099587  0.000344  0.003602 -0.285919  0.189875  0.015037\n",
       "6  -0.312178 -0.009525  0.000491  0.000775 -0.068506  0.015037  0.086243"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit1 = X.copy()\n",
    "edit1['noise'] = np.random.exponential(size = len(edit1))\n",
    "full_model_edit1 = OLS(y, edit1).fit()\n",
    "pd.DataFrame(beta_covariance(full_model_edit1, y, edit1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a column of noise decreases the standard error on our covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Create a separate dataset `edit2` with a new column `ratio` that is the ratio of a car's horsepower to its weight ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.121818</td>\n",
       "      <td>-4.303054</td>\n",
       "      <td>0.028160</td>\n",
       "      <td>0.185488</td>\n",
       "      <td>-6.913166</td>\n",
       "      <td>-4.750160</td>\n",
       "      <td>-0.882365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.303054</td>\n",
       "      <td>0.461514</td>\n",
       "      <td>-0.003772</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>0.063740</td>\n",
       "      <td>0.124963</td>\n",
       "      <td>0.016586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028160</td>\n",
       "      <td>-0.003772</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.010051</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.185488</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>-0.056566</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.004128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.913166</td>\n",
       "      <td>0.063740</td>\n",
       "      <td>-0.010051</td>\n",
       "      <td>-0.056566</td>\n",
       "      <td>3.630378</td>\n",
       "      <td>-0.149654</td>\n",
       "      <td>0.179257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.750160</td>\n",
       "      <td>0.124963</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.149654</td>\n",
       "      <td>0.215306</td>\n",
       "      <td>0.011878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.882365</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>-0.000189</td>\n",
       "      <td>-0.004128</td>\n",
       "      <td>0.179257</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.014124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6\n",
       "0  140.121818 -4.303054  0.028160  0.185488 -6.913166 -4.750160 -0.882365\n",
       "1   -4.303054  0.461514 -0.003772 -0.005929  0.063740  0.124963  0.016586\n",
       "2    0.028160 -0.003772  0.000125  0.000034 -0.010051  0.000124 -0.000189\n",
       "3    0.185488 -0.005929  0.000034  0.001408 -0.056566  0.000329 -0.004128\n",
       "4   -6.913166  0.063740 -0.010051 -0.056566  3.630378 -0.149654  0.179257\n",
       "5   -4.750160  0.124963  0.000124  0.000329 -0.149654  0.215306  0.011878\n",
       "6   -0.882365  0.016586 -0.000189 -0.004128  0.179257  0.011878  0.014124"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit2 = X.copy()\n",
    "edit2['ratio'] = edit2.hp / edit2.wt\n",
    "full_model_edit2 = OLS(y, edit2).fit()\n",
    "pd.DataFrame(beta_covariance(full_model_edit2, y, edit2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the ratio column increase the standard error of the intercept parameter, and the coefficients for horse power and weight. It decreases the standard error for the other parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3 Create a separate dataset `edit3` with a new column `combo` that is horsepower+displacement+weight+ Normal(0,.01) noise... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.257881</td>\n",
       "      <td>-3.276780</td>\n",
       "      <td>-0.989699</td>\n",
       "      <td>-1.078720</td>\n",
       "      <td>3.293435</td>\n",
       "      <td>-4.020364</td>\n",
       "      <td>1.006073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.276780</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.034776</td>\n",
       "      <td>-0.111351</td>\n",
       "      <td>0.111349</td>\n",
       "      <td>-0.035860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.989699</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.085003</td>\n",
       "      <td>-0.257711</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>-0.084071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.078720</td>\n",
       "      <td>0.034776</td>\n",
       "      <td>0.085003</td>\n",
       "      <td>0.084277</td>\n",
       "      <td>-0.255172</td>\n",
       "      <td>0.075535</td>\n",
       "      <td>-0.083122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.293436</td>\n",
       "      <td>-0.111351</td>\n",
       "      <td>-0.257711</td>\n",
       "      <td>-0.255172</td>\n",
       "      <td>0.773285</td>\n",
       "      <td>-0.229587</td>\n",
       "      <td>0.251944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.020364</td>\n",
       "      <td>0.111349</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>0.075535</td>\n",
       "      <td>-0.229587</td>\n",
       "      <td>0.205936</td>\n",
       "      <td>-0.071722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.006073</td>\n",
       "      <td>-0.035860</td>\n",
       "      <td>-0.084071</td>\n",
       "      <td>-0.083122</td>\n",
       "      <td>0.251944</td>\n",
       "      <td>-0.071722</td>\n",
       "      <td>0.082168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6\n",
       "0  85.257881 -3.276780 -0.989699 -1.078720  3.293435 -4.020364  1.006073\n",
       "1  -3.276780  0.443367  0.032300  0.034776 -0.111351  0.111349 -0.035860\n",
       "2  -0.989699  0.032300  0.086096  0.085003 -0.257711  0.072006 -0.084071\n",
       "3  -1.078720  0.034776  0.085003  0.084277 -0.255172  0.075535 -0.083122\n",
       "4   3.293436 -0.111351 -0.257711 -0.255172  0.773285 -0.229587  0.251944\n",
       "5  -4.020364  0.111349  0.072006  0.075535 -0.229587  0.205936 -0.071722\n",
       "6   1.006073 -0.035860 -0.084071 -0.083122  0.251944 -0.071722  0.082168"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit3 = X.copy()\n",
    "edit3['ratio'] = edit3.hp + edit3.disp + edit2.wt + np.random.normal(0,.01)\n",
    "full_model_edit3 = OLS(y, edit3).fit()\n",
    "pd.DataFrame(beta_covariance(full_model_edit3, y, edit3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of the intercept and coefficients for displacement, horsepower, and weight increase a lot. The standard error for the other coefficients slightly decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.4 If you could choose the different features in your data (either because you're running a lab experiment manipulating the X values, ... **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "I would want my features $x_1, x_2, ..., x_n$ to be as orthogonal as possible and as explanatory as possible. If we were to do this perfectly, this would lead to $X^TX$ having the squared length of the feature vectors on the diagonal and zeros off the diagonal. The covariance matrix would be a diagonal matrix with $\\frac{\\sigma^2}{||x_i||^2}$ on the diagonal, meaning that each $\\beta_i$ is uncorrelated with one another. \n",
    "\n",
    "Since our variables explain the dependent variable well, $\\sigma^2$ would also be small.\n",
    "\n",
    "These two conditions, orthogonalaity and predictive power, would make the regression model accurate and would decrease the standard error on our parameter estimates. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
